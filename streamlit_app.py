import os
import json
import ast
import re
import time
import uuid
import logging
import warnings
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union
from concurrent.futures import ThreadPoolExecutor
import copy # Added for deepcopying chat states

# Suppress DeltaGenerator warnings
warnings.filterwarnings(
    "ignore",
    category=UserWarning,
    module="streamlit.runtime.scriptrunner.script_runner",
)

import streamlit as st
from dotenv import load_dotenv

# Import our custom modules
from src.api.youtube_client import YouTubeClient
from src.api.gemini_client import GeminiClient
from src.analysis.video_analyzer import VideoAnalyzer
from src.analysis.scoring_engine import ScoringEngine
from src.analysis.recommendation_engine import RecommendationEngine
from src.utils.formatters import format_duration, format_published_date

# Load environment variables
load_dotenv()

# Setup logger for this module
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Constants
CHAT_HISTORY_FILE = "chat_history.json"
MAX_HISTORY_ITEMS = 20  # Maximum number of conversations to keep


def sanitize_for_json(data: Any) -> Any:
    """Recursively sanitize data to ensure it's JSON serializable."""
    if isinstance(data, datetime):
        return data.isoformat()
    elif isinstance(data, Path):
        return str(data)
    elif isinstance(data, dict):
        return {k: sanitize_for_json(v) for k, v in data.items()}
    elif isinstance(data, list):
        return [sanitize_for_json(item) for item in data]
    return data


def persist_chat_history(history: List[Dict[str, Any]]):
    """Persist the entire chat history to file."""
    # Ensure history is a list
    if not isinstance(history, list):
        st.error("Error: Chat history is not in the correct format for saving.")
        logger.error("Chat history is not a list during persist_chat_history.")
        st.error("Error: Chat history is not in the correct format for saving.")
        return

    try:
        sanitized_history = sanitize_for_json(history) # Sanitize before saving
        with open(CHAT_HISTORY_FILE, "w", encoding="utf-8") as f:
            json.dump(sanitized_history, f, indent=2)
        logger.info(f"Chat history persisted successfully with {len(sanitized_history)} items.")
    except Exception as e:
        logger.error(f"Error persisting chat history: {e}", exc_info=True)
        st.toast(f"âš ï¸ Error saving chat history: {str(e)}", icon="âŒ")


def load_chat_history() -> List[Dict[str, Any]]:
    """Load chat history from file if it exists."""
    logger.info(f"Attempting to load chat history from {CHAT_HISTORY_FILE}")
    if os.path.exists(CHAT_HISTORY_FILE):
        logger.info(f"File {CHAT_HISTORY_FILE} exists.")
        try:
            with open(CHAT_HISTORY_FILE, "r", encoding="utf-8") as f:
                history = json.load(f)
                logger.info(f"Successfully loaded {len(history)} chats from {CHAT_HISTORY_FILE}.")
                
                # Format numbers in all historical messages
                for conversation in history:
                    if "messages" in conversation:
                        for i, message in enumerate(conversation["messages"]):
                            if message.get("role") == "assistant" and "content" in message:
                                # Format numbers in the content
                                content = message["content"]
                                formatted_content = format_numbers_with_commas(content)
                                if formatted_content != content:
                                    print(f"[load_chat_history] Formatted message in conversation {conversation.get('id', 'unknown')}")
                                    conversation["messages"][i]["content"] = formatted_content
                
                st.session_state.conversation_history = history
                # Save the formatted history back to file
                persist_chat_history(history)
                return history
        except json.JSONDecodeError as e:
            logger.error(f"Error decoding JSON from {CHAT_HISTORY_FILE}: {e}")
        except FileNotFoundError:
            logger.error(f"File {CHAT_HISTORY_FILE} not found during open, though os.path.exists was true.")
    else:
        logger.info(f"File {CHAT_HISTORY_FILE} does not exist. Returning empty history.")
    
    # Create an empty history in case of errors
    st.session_state.conversation_history = []
    return []


def save_chat_history(conversation: Dict[str, Any]):
    """Save a conversation to the chat history."""
    history = load_chat_history()

    # Add timestamp if not present
    if "timestamp" not in conversation:
        conversation["timestamp"] = datetime.now().isoformat()

    # Add to history and keep only the most recent conversations
    history.insert(0, conversation)
    history = history[:MAX_HISTORY_ITEMS]

    # Save to file
    with open(CHAT_HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history, f, indent=2)


def init_session_state():
    """Initialize session state variables."""
    # Initialize current_chat_id if not present
    if "current_chat_id" not in st.session_state or not st.session_state.current_chat_id:
        st.session_state.current_chat_id = str(uuid.uuid4())
        # Initialize title and messages only if creating a truly new chat session ID
        st.session_state.current_chat_title = f"Chat {datetime.now().strftime('%Y-%m-%d %H:%M')}"
        st.session_state.messages = [
            {
                "role": "assistant",
                "content": "ðŸ‘‹ Hi there! I'm your YouTube Video Intelligence Assistant. "
                           "Paste a YouTube URL to get started with video analysis!",
            }
        ]
        st.session_state.analysis = None # Ensure analysis is reset for a new chat ID
        st.session_state.current_analysis = None # Ensure current_analysis is reset
        # Reset video context for new chat
        st.session_state.current_video_url = None

    # Ensure messages list exists, even if current_chat_id was already set
    # This handles cases where the app might have been reloaded without full re-initialization
    if "messages" not in st.session_state:
         st.session_state.messages = [
            {
                "role": "assistant",
                "content": "ðŸ‘‹ Hi there! I'm your YouTube Video Intelligence Assistant. "
                           "Paste a YouTube URL to get started with video analysis!",
            }
        ]

    # Ensure video context tracking exists
    if "current_video_url" not in st.session_state:
        st.session_state.current_video_url = None
    
    if "current_chat_title" not in st.session_state or not st.session_state.current_chat_title:
        # If current_chat_id exists but title doesn't, try to load from history or set a default
        existing_chat = next((c for c in st.session_state.get("conversation_history", []) if c.get("id") == st.session_state.current_chat_id), None)
        if existing_chat and existing_chat.get("title"):
            st.session_state.current_chat_title = existing_chat.get("title")
        else:
            st.session_state.current_chat_title = f"Chat {datetime.now().strftime('%Y-%m-%d %H:%M')}"
            
    # Critical fix: Ensure analysis data is loaded for the current chat
    # This ensures follow-up questions have access to the video context
    if ("current_analysis" not in st.session_state or st.session_state.current_analysis is None) and st.session_state.get("current_chat_id"):
        logger.info(f"Attempting to restore analysis data for chat: {st.session_state.current_chat_id}")
        # Find the chat in history
        history = st.session_state.get("conversation_history", [])
        existing_chat = next((c for c in history if c.get("id") == st.session_state.current_chat_id), None)
        
        if existing_chat and existing_chat.get("analysis"):
            # Restore both analysis objects from history
            st.session_state.analysis = copy.deepcopy(existing_chat.get("analysis"))
            st.session_state.current_analysis = copy.deepcopy(existing_chat.get("analysis"))
            
            # Extract video URL if available
            if isinstance(st.session_state.analysis, dict) and "metadata" in st.session_state.analysis:
                video_id = st.session_state.analysis.get("video_id")
                if video_id:
                    st.session_state.current_video_url = f"https://www.youtube.com/watch?v={video_id}"
                    logger.info(f"Restored video context: {st.session_state.current_video_url}")
            
            logger.info("Successfully restored analysis data for current chat")
        else:
            logger.info("No analysis data found in history for current chat")

    # Initialize API clients and engines
    if "analyzer" not in st.session_state:
        st.session_state.analyzer = VideoAnalyzer()

    if "scoring_engine" not in st.session_state:
        st.session_state.scoring_engine = ScoringEngine()

    if "recommendation_engine" not in st.session_state:
        st.session_state.recommendation_engine = RecommendationEngine()

    # Ensure Gemini client is initialized and working
    if "gemini_client" not in st.session_state:
        try:
            st.session_state.gemini_client = GeminiClient()
            print("Gemini client initialized successfully")
        except Exception as e:
            print(f"Error initializing Gemini client: {str(e)}")
            st.error(
                f"Failed to initialize Gemini AI client. Please check your API key and try again."
            )

    # Add debugging variables
    if "last_gemini_response" not in st.session_state:
        st.session_state.last_gemini_response = None

    # Initialize current conversation ID
    if "conversation_id" not in st.session_state:
        st.session_state.conversation_id = str(uuid.uuid4())

    # Initialize analysis state
    if "analysis" not in st.session_state:
        st.session_state.analysis = None

    # Initialize current analysis for contextual responses
    if "current_analysis" not in st.session_state:
        st.session_state.current_analysis = None

    # Load conversation history
    if "conversation_history" not in st.session_state:
        st.session_state.conversation_history = load_chat_history()

    # Flag for managing 'Thinking...' message display
    if "is_generating_response" not in st.session_state:
        st.session_state.is_generating_response = False

    # Store prompt being processed across reruns for 'Thinking...' indicator
    if "current_processing_prompt" not in st.session_state:
        st.session_state.current_processing_prompt = None

    if "gemini_futures" not in st.session_state:
        st.session_state.gemini_futures = {}

    if "thread_executor" not in st.session_state:
        st.session_state.thread_executor = ThreadPoolExecutor(max_workers=2)


def setup_sidebar():
    """Set up the sidebar components."""
    logger.info(f"ENTERING setup_sidebar. Conversation history count: {len(st.session_state.get('conversation_history', []))}")
    with st.sidebar:
        st.title("ðŸ’¬ Conversations")  # Original line 134
        if st.button("âž• New Chat", use_container_width=True, type="primary"):
            # *** IMPROVED FIX: Complete refactor of New Chat behavior ***
            # 1. Generate a completely new unique ID for this chat
            new_chat_id = str(uuid.uuid4())
            
            # 2. Store the new IDs and set a clear title
            st.session_state.current_chat_id = new_chat_id
            st.session_state.conversation_id = new_chat_id  # Keep both ID types consistent
            st.session_state.current_chat_title = f"New Chat {datetime.now().strftime('%Y-%m-%d %H:%M')}"
            
            # 3. Set the welcome message
            st.session_state.messages = [
                {
                    "role": "assistant",
                    "content": "ðŸ‘‹ Hi there! I'm your YouTube Video Intelligence Assistant. "
                               "Paste a YouTube URL to get started with video analysis!",
                }
            ]
            
            # 4. Reset analysis data completely
            st.session_state.analysis = None
            st.session_state.current_analysis = None
            
            # 5. Set critical flags to prevent auto-saving which causes duplication
            st.session_state.just_created_new_chat = True
            st.session_state.skip_save_for_current_chat = True
            
            # 6. Clear any existing URL parameters that might affect state
            st.query_params.clear()
            
            # 7. Log the new chat creation and trigger UI refresh
            logger.info(f"Started new chat with ID: {st.session_state.current_chat_id}")
            st.rerun() # Refresh the UI to show the new chat state with input box

        st.divider()  # This divider separates New Chat from Recent Chats

        # Show conversation history
        # logger.info(f"In setup_sidebar, number of chats in conversation_history: {len(st.session_state.get('conversation_history', []))}") # Moved to top of function
        if st.session_state.conversation_history:
            st.subheader("Recent Chats")
            for idx, conv in enumerate(st.session_state.conversation_history):
                # Safely get analysis and metadata object
                current_conv_analysis = conv.get("analysis")
                metadata_obj = None  # Use a clear variable name
                if isinstance(
                    current_conv_analysis, dict
                ):  # Check if analysis is a dict
                    metadata_obj = current_conv_analysis.get(
                        "metadata"
                    )  # Get the "metadata" dictionary

                # Determine button label based on conversation content
                button_label = "ðŸŽ¬ New Chat"  # Default

                if metadata_obj and isinstance(
                    metadata_obj, dict
                ):  # Check if metadata_obj exists and is a dict
                    video_title = metadata_obj.get("title")
                    channel_title = metadata_obj.get(
                        "channel_title"
                    )  # Use "channel_title" (snake_case) from chat_history.json

                    if channel_title and video_title:
                        button_label = f"ðŸŽ¬ {channel_title} - {video_title}"
                    elif video_title:  # If only title is found
                        button_label = f"ðŸŽ¬ {video_title}"
                    # If neither title nor channel_title are found,
                    # button_label remains its default "ðŸŽ¬ New Chat"
                elif conv.get("messages"):
                    first_message_content = conv["messages"][0].get("content", "")
                    is_initial_greeting = (
                        "Hi there! I'm your YouTube Video Intelligence Assistant."
                        in first_message_content
                    )
                    if not is_initial_greeting and first_message_content:
                        button_label = f"ðŸ’¬ {first_message_content[:30]}..."
                    # Else, it remains "ðŸŽ¬ New Chat"

                # Truncate button_label
                max_len = 45  # Slightly shorter to accommodate delete button
                if len(button_label) > max_len:
                    button_label = button_label[: max_len - 3] + "..."

                col1, col2 = st.columns([0.8, 0.2])  # Adjust column ratio as needed
                with col1:
                    if st.button(
                        button_label,
                        key=f"load_conv_idx_{idx}_{conv.get('id', 'no_id')}", # Ensure unique key with idx
                        use_container_width=True,
                    ):
                        save_current_conversation() # Save outgoing chat

                        st.session_state.current_chat_id = conv.get('id')
                        st.session_state.current_chat_title = conv.get('title', f"Chat {conv.get('id')[:8]}")
                        st.session_state.messages = copy.deepcopy(conv.get("messages", []))  # Use deepcopy
                        st.session_state.analysis = copy.deepcopy(conv.get("analysis", None))  # Use deepcopy
                        st.session_state.current_analysis = copy.deepcopy(conv.get("analysis", None))  # Use deepcopy for current_analysis as well
                        
                        # Restore video URL context from the conversation
                        if "video_url" in conv:
                            st.session_state.current_video_url = conv.get("video_url")
                            print(f"[DEBUG_TRACE] Restored video URL from loaded chat: {st.session_state.current_video_url}")
                        else:
                            # Try to find video URL in messages
                            for msg in reversed(st.session_state.messages):
                                if isinstance(msg, dict) and "video_url" in msg:
                                    st.session_state.current_video_url = msg.get("video_url")
                                    print(f"[DEBUG_TRACE] Restored video URL from message: {st.session_state.current_video_url}")
                                    break
                        
                        logger.info(f"Loaded chat: {st.session_state.current_chat_id}")
                        st.rerun()
                with col2:
                    if st.button(
                        "ðŸ—‘ï¸",
                        key=f"delete_conv_idx_{idx}_{conv.get('id', 'no_id')}", # Ensure unique key with idx
                        use_container_width=True,
                        help="Delete this chat",
                    ):
                        chat_id_to_delete = conv.get('id')
                        logger.info(f"Attempting to delete chat: {chat_id_to_delete}")
                        
                        # Filter out the conversation to delete
                        st.session_state.conversation_history = [
                            c
                            for c in st.session_state.get("conversation_history", []) # Add .get for safety
                            if c.get("id") != chat_id_to_delete
                        ]
                        persist_chat_history(st.session_state.conversation_history)
                        
                        # If the deleted chat was the current one, reset to a new chat state
                        if st.session_state.current_chat_id == chat_id_to_delete:
                            logger.info(f"Current chat {chat_id_to_delete} was deleted. Resetting to new chat state.")
                            st.session_state.current_chat_id = str(uuid.uuid4())
                            st.session_state.current_chat_title = f"New Chat {datetime.now().strftime('%Y-%m-%d %H:%M')}"
                            st.session_state.messages = [
                                {
                                    "role": "assistant",
                                    "content": "ðŸ‘‹ Hi there! I'm your YouTube Video Intelligence Assistant. "
                                               "Paste a YouTube URL to get started with video analysis!",
                                }
                            ]
                            st.session_state.analysis = None
                            st.session_state.current_analysis = None
                        
                        st.rerun()

        st.divider()

        # Add a clear history button
        if st.button("ðŸ—‘ï¸ Clear All History", type="secondary"):
            if os.path.exists(CHAT_HISTORY_FILE):
                os.remove(CHAT_HISTORY_FILE)
            st.session_state.conversation_history = []
            st.session_state.messages = [
                {
                    "role": "assistant",
                    "content": "ðŸ‘‹ Hi there! I'm your YouTube Video Intelligence Assistant. "
                    "Paste a YouTube URL to get started with video analysis!",
                }
            ]
            st.rerun()


def setup_ui():
    """Set up the Streamlit UI components."""
    st.set_page_config(
        page_title="YouTube Video Intelligence",
        page_icon="ðŸŽ¥",
        layout="wide",
        initial_sidebar_state="expanded",
    )

    # Sidebar
    setup_sidebar()

    # Main content
    st.title("ðŸŽ¬ YouTube Video Intelligence Chatbot")
    st.caption("Analyze and optimize your YouTube videos with AI")


def format_recommendation(
    rec_type: str, rec_desc: str, justification: str = ""
) -> None:
    """Format a single recommendation with consistent styling.

    Args:
        rec_type: The type/action of the recommendation (e.g., "Add", "Emphasize")
        rec_desc: The recommendation description/suggestion
        justification: Optional justification for the recommendation
    """
    # Clean up the action/type
    action = rec_type.strip()
    if action.endswith(":"):
        action = action[:-1].strip()
    action = action.capitalize()

    # Clean up the suggestion
    suggestion = rec_desc.strip()
    if suggestion.startswith(":"):
        suggestion = suggestion[1:].strip()

    # Clean up justification
    justification_text = justification.strip() if justification else ""
    if justification_text.startswith(":"):
        justification_text = justification_text[1:].strip()

    # Display the formatted recommendation
    st.markdown(
        f"- **[{action}]** <span style='color:white;'>{suggestion}</span>",
        unsafe_allow_html=True,
    )
    if justification_text:
        st.markdown(
            f"    - <span style='color:white; font-style:italic;'>{justification_text}</span>",
            unsafe_allow_html=True,
        )


def display_recommendation(rec: Any) -> None:
    """Display a single recommendation in the appropriate format.

    Args:
        rec: The recommendation data (dict, str, or other format)
    """
    if not isinstance(rec, dict):
        # If it's not a dictionary, just display it as is
        st.markdown(f"- {str(rec)}")
        return

    # Handle different recommendation formats
    if "type" in rec and "description" in rec:
        # Format with type and description fields
        rec_type = rec.get("type", "").replace("'", "").strip()
        rec_desc = rec.get("description", "").replace("'", "").strip()
        justification = rec.get("justification", "")
        format_recommendation(rec_type, rec_desc, justification)

    elif "action" in rec and "suggestion" in rec and "justification" in rec:
        # New standardized format with action/suggestion/justification
        rec_type = rec.get("action", "")
        rec_desc = rec.get("suggestion", "")
        justification = rec.get("justification", "")
        format_recommendation(rec_type, rec_desc, justification)

    elif "text" in rec:
        # Simple text format
        st.markdown(f"- {rec['text']}")

    else:
        # Fallback: display all key-value pairs
        formatted_rec = ", ".join([f"{k}: {v}" for k, v in rec.items()])
        st.markdown(f"- {formatted_rec}")


def display_analysis_results(analysis: Dict[str, Any]) -> None:
    """Display video analysis results in a structured format.

    Args:
        analysis: The analysis results from the VideoAnalyzer
    """
    # Debug information to verify what data we have
    print(f"[display_analysis_results] Analysis type: {type(analysis)}")
    if hasattr(analysis, 'keys'):
        print(f"[display_analysis_results] Analysis keys: {list(analysis.keys())}")
    else:
        print(f"[display_analysis_results] Analysis doesn't have keys method: {analysis}")
    
    # Check for specific analysis sections we expect
    if isinstance(analysis, dict):
        if "analysis" in analysis:
            print(f"[display_analysis_results] 'analysis' key present with type: {type(analysis['analysis'])}")
        if "metadata" in analysis:
            print(f"[display_analysis_results] 'metadata' key present")
        if "scores" in analysis:
            print(f"[display_analysis_results] 'scores' key present")
    
    # Make sure we don't accidentally convert analysis to plain text
    if isinstance(analysis, str) and (analysis.startswith('{') or analysis.startswith('[')):
        print(f"[display_analysis_results] WARNING: Analysis appears to be a string representation of JSON!")
        try:
            # Try to parse it back to a dictionary
            import json
            analysis = json.loads(analysis)
            print(f"[display_analysis_results] Successfully parsed string back to dict with keys: {analysis.keys()}")
        except Exception as e:
            print(f"[display_analysis_results] Failed to parse string as JSON: {str(e)}")

    # Initialize thumbnail_analysis with a default structure at the start of the function
    thumbnail_analysis = {
        "score": 0.0,
        "design_effectiveness": {
            "analysis": "",
            "strengths": [],
            "weaknesses": [],
            "recommendations": [],
        },
        "visual_elements": {
            "analysis": "",
            "strengths": [],
            "weaknesses": [],
            "recommendations": [],
        },
        "thumbnail_optimization": {
            "analysis": "",
            "strengths": [],
            "weaknesses": [],
            "recommendations": [],
        },
    }

    # Update with actual data if available
    if "thumbnail_analysis" in analysis and isinstance(
        analysis["thumbnail_analysis"], dict
    ):
        thumbnail_analysis.update(analysis["thumbnail_analysis"])
    elif (
        "analysis" in analysis
        and "thumbnail_analysis" in analysis["analysis"]
        and isinstance(analysis["analysis"]["thumbnail_analysis"], dict)
    ):
        thumbnail_analysis.update(analysis["analysis"]["thumbnail_analysis"])
    elif (
        "scores" in analysis
        and "factors" in analysis["scores"]
        and "hook_quality" in analysis["scores"]["factors"]
        and isinstance(analysis["scores"]["factors"]["hook_quality"], dict)
        and "hook_analysis" in analysis["scores"]["factors"]["hook_quality"]
        and isinstance(
            analysis["scores"]["factors"]["hook_quality"]["hook_analysis"], dict
        )
    ):
        hook_data = analysis["scores"]["factors"]["hook_quality"]["hook_analysis"]
        if "thumbnail_analysis" in hook_data and isinstance(
            hook_data["thumbnail_analysis"], dict
        ):
            thumbnail_analysis.update(hook_data["thumbnail_analysis"])

    # Debug print statements to understand the analysis data structure
    print("\n\n==== DEBUG: ANALYSIS DATA STRUCTURE =====")
    print("Top-level keys in analysis:", list(analysis.keys()))

    if "title_analysis" in analysis:
        print(
            "Title analysis found with keys:", list(analysis["title_analysis"].keys())
        )
        if "score" in analysis["title_analysis"]:
            print(f"Title analysis score: {analysis['title_analysis']['score']}")
    else:
        print("No title_analysis found in analysis dictionary")

    if "thumbnail_analysis" in analysis:
        print(
            "Thumbnail analysis found with keys:",
            list(analysis["thumbnail_analysis"].keys()),
        )
        if "score" in analysis["thumbnail_analysis"]:
            print(
                f"Thumbnail analysis score: {analysis['thumbnail_analysis']['score']}"
            )
    else:
        print("No thumbnail_analysis found in analysis dictionary")

    if "scores" in analysis and "factors" in analysis["scores"]:
        print("Performance factors:", list(analysis["scores"]["factors"].keys()))
        if "hook" in analysis["scores"]["factors"]:
            print(f"Hook factor data: {analysis['scores']['factors']['hook']}")
    print("==== END DEBUG ====\n\n")
    # Debug section to understand available data - REMOVED
    # with st.expander("Debug Information", expanded=False):
    #     st.write("### Analysis Data Structure")
    #     st.write("Top-level keys in analysis dictionary:", list(analysis.keys()))
    #
    #     if "title_analysis" in analysis:
    #         st.write("Title analysis is present with keys:", list(analysis["title_analysis"].keys()))
    #         if "score" in analysis["title_analysis"]:
    #             st.write(f"Title analysis score: {analysis['title_analysis']['score']}")
    #     else:
    #         st.write("Title analysis is NOT present in the analysis dictionary")
    #
    #     if "thumbnail_analysis" in analysis:
    #         st.write("Thumbnail analysis is present with keys:", list(analysis["thumbnail_analysis"].keys()))
    #         if "score" in analysis["thumbnail_analysis"]:
    #             st.write(f"Thumbnail analysis score: {analysis['thumbnail_analysis']['score']}")
    #     else:
    #         st.write("Thumbnail analysis is NOT present in the analysis dictionary")
    #
    #     if "scores" in analysis and "factors" in analysis["scores"]:
    #         st.write("Performance factors available:", list(analysis["scores"]["factors"].keys()))
    #         if "hook" in analysis["scores"]["factors"]:
    #             st.write(f"Hook score in factors: {analysis['scores']['factors']['hook'].get('score', 'Not set')}")

    # Display video metadata
    if "metadata" in analysis:
        metadata = analysis["metadata"]

        # Display title and channel name spanning full width
        st.header(f"ðŸ“Š Analysis: {metadata.get('title', 'Unknown Video')}")
        st.subheader(f"ðŸ“º {metadata.get('channel_title', 'Unknown Channel')}")

        # Display video metadata in two columns
        col1, col2 = st.columns([1, 3])

        # Left column - Thumbnail
        with col1:
            thumbnail_displayed = False

            if "thumbnail" in analysis:
                # Debug thumbnail data
                print(
                    f"Thumbnail data keys: {analysis['thumbnail'].keys() if analysis['thumbnail'] else 'None'}"
                )

                # First try using the URL
                thumbnail_url = analysis["thumbnail"].get("url")
                video_id = analysis.get("video_id")
                video_url = (
                    f"https://www.youtube.com/watch?v={video_id}" if video_id else None
                )

                if (
                    thumbnail_url
                    and isinstance(thumbnail_url, str)
                    and thumbnail_url.startswith("http")
                ):
                    try:
                        # Create a clickable thumbnail using HTML
                        if video_url:
                            # Use HTML to create a clickable image
                            html = f"""
                            <a href="{video_url}" target="_blank">
                                <img src="{thumbnail_url}" style="width:100%">
                            </a>
                            """
                            st.markdown(html, unsafe_allow_html=True)
                        else:
                            # Fallback to regular image if no video URL
                            st.image(
                                thumbnail_url,
                                caption="Thumbnail",
                                use_container_width=True,
                            )
                        thumbnail_displayed = True
                        print(
                            f"Successfully displayed thumbnail from URL: {thumbnail_url}"
                        )
                    except Exception as e:
                        print(f"Error displaying thumbnail from URL: {str(e)}")
                        # Continue to try local path

                # If URL fails, try local path
                if not thumbnail_displayed:
                    local_path = analysis["thumbnail"].get("local_path")
                    if local_path and os.path.exists(local_path):
                        try:
                            if video_url:
                                # For local images, we need to read the file and convert to base64
                                import base64
                                from pathlib import Path

                                # Read image file and convert to base64
                                img_format = (
                                    Path(local_path).suffix.replace(".", "").lower()
                                )
                                with open(local_path, "rb") as img_file:
                                    img_str = base64.b64encode(img_file.read()).decode()

                                # Create HTML with the base64 image
                                html = f"""
                                <a href="{video_url}" target="_blank">
                                    <img src="data:image/{img_format};base64,{img_str}" style="width:100%">
                                </a>
                                """
                                st.markdown(html, unsafe_allow_html=True)
                            else:
                                # Fallback to regular image if no video URL
                                st.image(
                                    local_path,
                                    caption="Thumbnail",
                                    use_container_width=True,
                                )
                            thumbnail_displayed = True
                            print(
                                f"Successfully displayed thumbnail from local path: {local_path}"
                            )
                        except Exception as e2:
                            print(
                                f"Error displaying thumbnail from local path: {str(e2)}"
                            )
                            # Continue to placeholder

            # If no thumbnail was displayed, show a placeholder
            if not thumbnail_displayed:
                print("Using placeholder image for thumbnail")
                import numpy as np
                from PIL import Image as PILImage
                import io
                import base64

                # Create a dark gray placeholder image
                img_array = np.ones((180, 320, 3), dtype=np.uint8) * 64
                placeholder_img = PILImage.fromarray(img_array)

                if video_url:
                    # Convert PIL image to base64
                    buffer = io.BytesIO()
                    placeholder_img.save(buffer, format="PNG")
                    img_str = base64.b64encode(buffer.getvalue()).decode()

                    # Create HTML with the base64 image
                    html = f"""
                    <a href="{video_url}" target="_blank">
                        <img src="data:image/png;base64,{img_str}" style="width:100%">
                    </a>
                    """
                    st.markdown(html, unsafe_allow_html=True)
                else:
                    # Regular non-clickable placeholder
                    st.image(
                        placeholder_img, caption="Thumbnail", use_container_width=True
                    )

        # Right column - Metrics and description
        with col2:
            # Create metrics row
            metrics_cols = st.columns(4)
            with metrics_cols[0]:
                st.metric("Views", f"{int(metadata.get('view_count', 0)):,}")
            with metrics_cols[1]:
                st.metric("Likes", f"{int(metadata.get('like_count', 0)):,}")
            with metrics_cols[2]:
                st.metric("Comments", f"{int(metadata.get('comment_count', 0)):,}")
            with metrics_cols[3]:
                st.metric("Duration", metadata.get("formatted_duration", "Unknown"))

            # Show description
            if metadata.get("description"):
                with st.expander("ðŸ“ Description"):
                    st.text(metadata.get("description"))

    # Thumbnail analysis is now displayed in the Hook Analysis section
    # Display AI analysis
    if "analysis" in analysis:
        ai_analysis = analysis["analysis"]

        st.subheader("ðŸ¤– AI Analysis")

    # Display scores if available
    if "scores" in analysis:
        scores = analysis["scores"]

        # Define the performance categories
        performance_categories = [
            {"name": "Hook", "key": "hook_quality", "emoji": "ðŸŽ£"},
            {"name": "SEO Optimization", "key": "seo_optimization", "emoji": "ðŸ”"},
            {"name": "Content Quality", "key": "content_quality", "emoji": "ðŸ“"},
            {
                "name": "Audience Engagement",
                "key": "engagement_metrics",
                "emoji": "ðŸ‘¥",
            },
            {
                "name": "Technical Quality",
                "key": "technical_quality",
                "emoji": "âš™ï¸",
            },
        ]

        # Compute overall score as average of available category scores
        if "factors" in scores:
            factors = scores["factors"]
            available_scores = []

            # Get scores from all factors
            for category in performance_categories:
                factor_key = category["key"]
                if factor_key in factors and "score" in factors[factor_key]:
                    try:
                        score_value = min(5.0, float(factors[factor_key]["score"]))
                        available_scores.append(score_value)
                    except (ValueError, TypeError):
                        pass

            # Calculate overall score
            if available_scores:
                computed_overall_score = sum(available_scores) / len(available_scores)
                overall_score = min(5.0, round(computed_overall_score, 1))
            else:
                overall_score = min(5.0, float(scores.get("overall_score", 0)))

            st.subheader("ðŸ“ˆ Performance Scores")
            st.markdown(f"### Overall Score: {overall_score}/5")
            # Ensure progress value is between 0.0 and 1.0
            progress_value = min(1.0, max(0.0, overall_score / 5.0))
            st.progress(progress_value)

            # Factor scores
            if "factors" in scores:
                # Create columns for each factor
                cols = st.columns(len(performance_categories))

                # Display each performance category
                for i, category in enumerate(performance_categories):
                    with cols[i]:
                        factor_key = category["key"]
                        factor_data = factors.get(
                            factor_key, {"score": 0, "description": "No data available"}
                        )

                        # Display score with stars - cap at 5.0
                        score = min(5.0, float(factor_data.get("score", 0)))
                        stars = "â­" * int(score) + "â˜†" * (5 - int(score))

                        st.markdown(f"### {category['emoji']} {category['name']}")
                        st.markdown(f"**{stars}** ({score}/5)")

                        # Get rating description based on score
                        rating_description = "No data available"
                        if "description" in factor_data:
                            rating_description = factor_data["description"]
                        else:
                            # Generate description based on score
                            if score >= 4.5:
                                rating_description = "Excellent"
                            elif score >= 3.5:
                                rating_description = "Good"
                            elif score >= 2.5:
                                rating_description = "Average"
                            elif score >= 1.5:
                                rating_description = "Below Average"
                            else:
                                rating_description = "Poor"

                        st.caption(rating_description)

    # Main Hook Analysis section
    st.markdown("## ðŸŽ£ Hook Analysis")

    # Get title_analysis from multiple possible locations
    title_analysis = None
    if "title_analysis" in analysis:
        title_analysis = analysis["title_analysis"]
    elif "analysis" in analysis and "title_analysis" in analysis["analysis"]:
        title_analysis = analysis["analysis"]["title_analysis"]
    elif (
        "scores" in analysis
        and "factors" in analysis["scores"]
        and "hook_quality" in analysis["scores"]["factors"]
    ):
        # Try to get from hook_analysis in scores
        hook_data = analysis["scores"]["factors"]["hook_quality"]
        if isinstance(hook_data, dict) and "hook_analysis" in hook_data:
            title_analysis = {
                "analysis": hook_data["hook_analysis"].get("title_analysis", "")
            }

    # Title Analysis subsection
    st.markdown("### ðŸ’¬ Title Analysis")
    with st.expander("View Title Analysis Details", expanded=False):
        if title_analysis:
            # Check for error in title analysis - only if error has a non-null value
            if isinstance(title_analysis, dict) and "error" in title_analysis and title_analysis["error"] is not None:
                st.warning(f"Error in title analysis: {title_analysis['error']}")

                # Try to get title information from metadata
                if "metadata" in analysis and "title" in analysis["metadata"]:
                    video_title = analysis["metadata"]["title"]
                    st.info(f"Video title: {video_title}")

                    # Try to get hook quality score from scores
                    if (
                        "scores" in analysis
                        and "factors" in analysis["scores"]
                        and "hook_quality" in analysis["scores"]["factors"]
                    ):
                        hook_data = analysis["scores"]["factors"]["hook_quality"]
                        if isinstance(hook_data, dict) and "score" in hook_data:
                            hook_score = min(5.0, float(hook_data["score"]))
                            stars = "â­" * int(hook_score) + "â˜†" * (5 - int(hook_score))
                            st.markdown(
                                f"**Hook Quality Score: {stars} ({hook_score}/5)**"
                            )

                            # Display hook description if available
                            if "description" in hook_data:
                                st.markdown(
                                    f"**Assessment:** {hook_data['description']}"
                                )

                    # Display fallback message
                    st.info(
                        "The detailed title analysis could not be generated. The hook quality score above includes both title and thumbnail assessment."
                    )
            elif isinstance(title_analysis, dict):
                # Calculate title score if provided
                if "score" in title_analysis:
                    try:
                        title_score = min(5.0, float(title_analysis["score"]))
                        stars = "â­" * int(title_score) + "â˜†" * (5 - int(title_score))
                        st.markdown(f"**Title Score: {stars} ({title_score}/5)**")
                    except (ValueError, TypeError) as e:
                        st.warning(f"Title score not available: {e}")

                # Display title analysis content with proper formatting
                if "analysis" in title_analysis and title_analysis["analysis"]:
                    st.markdown("**Analysis:**")
                    st.markdown(title_analysis["analysis"])
                elif (
                    "effectiveness" in title_analysis
                    and title_analysis["effectiveness"]
                ):
                    st.markdown("**Effectiveness:**")

                    # Parse the effectiveness content
                    effectiveness_text = title_analysis["effectiveness"]

                    # Ensure effectiveness_text is a string
                    if not isinstance(effectiveness_text, str):
                        effectiveness_text = str(effectiveness_text)

                    # Check if it's in JSON-like format with quotes and curly braces
                    if effectiveness_text.strip().startswith(
                        "{"
                    ) and effectiveness_text.strip().endswith("}"):
                        try:
                            import json
                            import ast

                            # Try to parse as JSON or Python dict
                            try:
                                parsed_content = json.loads(effectiveness_text)
                            except:
                                try:
                                    # Try using ast.literal_eval for Python dict-like strings
                                    parsed_content = ast.literal_eval(
                                        effectiveness_text
                                    )
                                except:
                                    parsed_content = None

                            if parsed_content and isinstance(parsed_content, dict):
                                # Format each key-value pair as a bullet point
                                for key, value in parsed_content.items():
                                    key = key.strip("'").replace("_", " ").title()
                                    st.markdown(f"â€¢ **{key}:** {value}")
                            else:
                                # If parsing fails, display as is
                                st.markdown(effectiveness_text)
                        except Exception:
                            # If parsing fails, display as is
                            st.markdown(effectiveness_text)
                    else:
                        # Not JSON format, display as is
                        st.markdown(effectiveness_text)

                # Display recommendations if available
                if (
                    "recommendations" in title_analysis
                    and title_analysis["recommendations"]
                ):
                    st.markdown("**Recommendations:**")
                    if isinstance(title_analysis["recommendations"], list):
                        # Display each recommendation using the helper function
                        for rec in title_analysis["recommendations"]:
                            display_recommendation(rec)
                    elif isinstance(title_analysis["recommendations"], str):
                        # Try to parse JSON string if it looks like JSON
                        try:
                            import json
                            import ast

                            # Try different parsing methods
                            try:
                                recs_list = json.loads(
                                    title_analysis["recommendations"]
                                )
                            except Exception:
                                try:
                                    recs_list = ast.literal_eval(
                                        title_analysis["recommendations"]
                                    )
                                except Exception:
                                    recs_list = None

                            if isinstance(recs_list, list):
                                for rec in recs_list:
                                    display_recommendation(rec)
                            elif recs_list is not None:
                                st.markdown(str(recs_list))
                            else:
                                # If not JSON, try to parse as plain text with bullet points
                                lines = title_analysis["recommendations"].split("\n")
                                for line in lines:
                                    line = line.strip()
                                    if line.startswith(("-", "*", "â€¢")) or (
                                        len(line) > 2
                                        and line[0].isdigit()
                                        and line[1:].startswith(". ")
                                    ):
                                        st.markdown(line)
                                    elif line:  # Only add non-empty lines
                                        st.markdown(f"- {line}")
                        except Exception as e:
                            st.markdown(title_analysis["recommendations"])
                            st.error(f"Error parsing recommendations: {str(e)}")
                    else:
                        st.markdown(
                            "- No recommendations available in the expected format."
                        )
                        raw_rec = title_analysis["recommendations"]
                        if isinstance(
                            raw_rec, (dict, list, str, int, float, bool, type(None))
                        ):
                            st.json(raw_rec)
                        else:
                            st.warning("Raw recommendations data is not displayable.")

    # Thumbnail Analysis section - moved outside of Title Analysis
    st.markdown("### ðŸ˜‹ Thumbnail Analysis")
    with st.expander("View Thumbnail Analysis Details", expanded=False):
        # Debug output - keep this for now to help with troubleshooting
        # st.json({"thumbnail_analysis_data": thumbnail_analysis})

        if thumbnail_analysis:
            # Display thumbnail analysis
            if isinstance(thumbnail_analysis, dict):
                # Display thumbnail score if available
                if "score" in thumbnail_analysis:
                    try:
                        thumbnail_score = min(5.0, float(thumbnail_analysis["score"]))
                        stars = "â­" * int(thumbnail_score) + "â˜†" * (
                            5 - int(thumbnail_score)
                        )
                        st.markdown(
                            f"**Thumbnail Score: {stars} ({thumbnail_score:.1f}/5)**"
                        )
                    except (ValueError, TypeError) as e:
                        st.warning(f"Thumbnail score not available: {e}")

                # Helper function to display content
                def display_content(content, prefix=""):
                    if isinstance(content, dict):
                        for key, value in content.items():
                            key_display = key.replace("_", " ").title()
                            if isinstance(value, dict):
                                st.markdown(f"**{key_display}**")
                                display_content(value, prefix + "  ")
                            elif isinstance(value, (list, tuple)):
                                st.markdown(f"**{key_display}:**")
                                for item in value:
                                    if isinstance(item, (dict, list)):
                                        display_content(item, prefix + "  ")
                                    else:
                                        st.markdown(f"{prefix}â€¢ {item}")
                            else:
                                st.markdown(f"**{key_display}:** {value}")
                    elif isinstance(content, (list, tuple)):
                        for item in content:
                            if isinstance(item, (dict, list)):
                                display_content(item, prefix + "  ")
                            else:
                                st.markdown(f"{prefix}- {item}")
                    elif content:  # Only display non-empty strings/values
                        st.markdown(content)

                # Display main analysis content
                for key in ["analysis", "effectiveness"]:
                    if key in thumbnail_analysis and thumbnail_analysis[key]:
                        content = thumbnail_analysis[key]
                        if key == "analysis" or (
                            key == "effectiveness"
                            and "analysis" not in thumbnail_analysis
                        ):
                            st.markdown(
                                f"**{key.title()}:**"
                                if key == "effectiveness"
                                else "**Analysis:**"
                            )
                            display_content(content)

                # Display design effectiveness, visual elements, and optimization
                sections = [
                    ("Design Effectiveness", "design_effectiveness"),
                    ("Visual Elements", "visual_elements"),
                    ("Thumbnail Optimization", "thumbnail_optimization"),
                ]

                for section_title, section_key in sections:
                    if (
                        section_key in thumbnail_analysis
                        and thumbnail_analysis[section_key]
                    ):
                        section_data = thumbnail_analysis[section_key]
                        st.markdown(f"**{section_title}:**")

                        # Try to parse string as JSON/dict if needed
                        if isinstance(section_data, str):
                            if section_data.strip().startswith(
                                "{"
                            ) and section_data.strip().endswith("}"):
                                try:
                                    import json
                                    import ast

                                    try:
                                        section_data = json.loads(section_data)
                                    except:
                                        section_data = ast.literal_eval(section_data)
                                except:
                                    pass
                            else:
                                st.markdown(section_data)
                                continue

                        # Display the section content
                        if isinstance(section_data, dict):
                            display_content(section_data)
                        else:
                            st.markdown(section_data)

                # Display any remaining top-level keys that haven't been displayed yet
                displayed_keys = {
                    "score",
                    "analysis",
                    "effectiveness",
                    "design_effectiveness",
                    "visual_elements",
                    "thumbnail_optimization",
                    "recommendations",
                }
                remaining_keys = set(thumbnail_analysis.keys()) - displayed_keys

                # Display recommendations if available
                if (
                    "recommendations" in thumbnail_analysis
                    and thumbnail_analysis["recommendations"]
                ):
                    st.markdown("**Recommendations:**")
                    recs = thumbnail_analysis["recommendations"]
                    if isinstance(recs, str):
                        # Try to parse JSON string if it looks like JSON
                        if recs.strip().startswith("{") and recs.strip().endswith("}"):
                            try:
                                import json
                                import ast

                                try:
                                    recs = json.loads(recs)
                                except:
                                    recs = ast.literal_eval(recs)
                            except:
                                pass

                    if isinstance(recs, list):
                        for rec in recs:
                            if isinstance(rec, dict):
                                display_recommendation(rec)
                            else:
                                st.markdown(f"â€¢ {rec}")
                    elif isinstance(recs, dict):
                        display_recommendation(recs)
                    elif recs:  # Only display if not empty string
                        st.markdown(f"â€¢ {recs}")
    # Get scores from analysis at the beginning of the function
    scores = analysis.get("scores", {})
    # The scores are directly in the scores dict, not under 'factors' key
    factor_scores = {}
    for factor in [
        "hook_quality",
        "content_quality",
        "seo_optimization",
        "engagement_metrics",
        "technical_quality",
    ]:
        if factor in scores:
            try:
                factor_scores[factor] = (
                    float(scores[factor]) * 5.0
                )  # Convert to 5-point scale
            except Exception:
                pass

    # SEO Optimization
    st.markdown("## ðŸ” SEO Optimization")
    ai_analysis = analysis.get("analysis", {})
    factors = analysis.get("scores", {}).get("factors", {})
    if ai_analysis.get("seo_optimization"):
        content = ai_analysis["seo_optimization"]
        seo_score = None
        try:
            seo_score = float(factors.get("seo_optimization", {}).get("score", None))
            seo_score = min(5.0, seo_score)
        except (TypeError, ValueError):
            seo_score = None
        # Define the SEO display function first, so it's available everywhere
        def display_seo_content(content, prefix=""):
            if isinstance(content, dict):
                # First try to extract key fields of interest
                important_fields = [
                    "title_effectiveness", 
                    "description", 
                    "tags", 
                    "thumbnail_clickability"
                ]
                recommendations = None
                
                # Special handling for recommendations
                if "recommendations" in content:
                    recommendations = content["recommendations"]
                
                # Display main fields
                for key in important_fields:
                    if key in content and content[key]:
                        key_display = key.replace("_", " ").title()
                        st.markdown(f"**{key_display}:** {content[key]}")
                
                # Display recommendations last
                if recommendations:
                    st.markdown("**Recommendations:**")
                    if isinstance(recommendations, list):
                        for rec in recommendations:
                            st.markdown(f"- {rec}")
                    else:
                        st.markdown(recommendations)
                        
                # Handle any other keys
                for key, value in content.items():
                    if key not in important_fields and key != "recommendations" and key != "score":
                        key_display = key.replace("_", " ").title()
                        if isinstance(value, (dict, list)):
                            st.markdown(f"**{key_display}:**")
                            display_seo_content(value, prefix + "  ")
                        else:
                            st.markdown(f"**{key_display}:** {value}")
            
            elif isinstance(content, list):
                for item in content:
                    if isinstance(item, (dict, list)):
                        display_seo_content(item, prefix + "  ")
                    else:
                        st.markdown(f"{prefix}- {item}")
            else:
                st.markdown(f"{prefix}{content}")
                
        with st.expander("View SEO Optimization Details", expanded=False):
            if seo_score is not None:
                stars = "â­" * int(seo_score) + "â˜†" * (5 - int(seo_score))
                st.markdown(f"**SEO Optimization Score: {stars} ({seo_score:.1f}/5)**")
            # Debug statements removed - UI is now clean
            
            if content:
                # Skip string display that contains raw JSON - only use our formatter
                if isinstance(content, (int, float)):
                    st.markdown(str(content))
                elif isinstance(content, str):
                    # Try to parse JSON from string
                    try:
                        # Find potential JSON in the string
                        import json
                        import re
                        
                        # First check if the entire string is valid JSON
                        json_parsed = False
                        try:
                            json_data = json.loads(content)
                            display_seo_content(json_data)
                            json_parsed = True
                        except json.JSONDecodeError:
                            pass
                            
                        # Only continue if we haven't successfully parsed JSON yet
                        if not json_parsed:
                            # Look for JSON object pattern within the string
                            json_pattern = r'\{[\s\S]*\}'
                            match = re.search(json_pattern, content)
                            
                            if match:
                                potential_json = match.group(0)
                                try:
                                    json_data = json.loads(potential_json)
                                    display_seo_content(json_data)
                                    json_parsed = True
                                except json.JSONDecodeError:
                                    pass
                    
                    except Exception as e:
                        st.warning(f"Error parsing SEO data: {str(e)}")
                    
                    # If we get here and haven't parsed JSON successfully, display the cleaned string
                    if not json_parsed:
                        cleaned = re.sub(r"SEO Optimization \([\-\d.]+/5\)\*\*:?:?\s*", "", content)
                        # Remove "SEO Optimization (3/5)" line that might be in the string
                        cleaned = re.sub(r"SEO Optimization \([\d\.]+/5\)\s*\n", "", cleaned)
                        st.markdown(cleaned)
                elif isinstance(content, (dict, list)):
                    # Display structured data nicely instead of raw JSON
                    display_seo_content(content)
                else:
                    st.warning("SEO optimization analysis data is not displayable.")
            else:
                st.markdown("No SEO optimization analysis available.")

    # Content Analysis section (main section)
    st.markdown("## ðŸ“ Content Analysis")
    factors = analysis.get("scores", {}).get("factors", {})
    content_score = None
    try:
        content_score = float(factors.get("content_quality", {}).get("score", None))
        content_score = min(5.0, content_score)
    except (TypeError, ValueError):
        content_score = None

    # Robust extraction, similar to Thumbnail Analysis
    def try_parse_json_block(s):
        import json, re
        # Find the first JSON block inside triple backticks (optionally with 'json')
        match = re.search(r"```(?:json)?\s*({[\s\S]+?})\s*```", s, re.IGNORECASE)
        if match:
            try:
                return json.loads(match.group(1))
            except Exception as e:
                print("JSON parse error:", e)
        # Fallback: try to parse any JSON-looking substring
        s_strip = s.strip()
        brace_match = re.search(r"({[\s\S]+})", s_strip)
        if brace_match:
            try:
                return json.loads(brace_match.group(1))
            except Exception as e:
                print("JSON parse error (fallback):", e)
        return None

    content_analysis_data = (
        analysis.get("content_quality_analysis")
        or analysis.get("analysis", {}).get("content_quality_detail")
        or analysis.get("analysis", {}).get("content_quality")
        or analysis.get("content_quality")
    )

    if isinstance(content_analysis_data, str):
        parsed = try_parse_json_block(content_analysis_data)
        if parsed:
            content_analysis_data = parsed

    with st.expander("View Content Analysis Details", expanded=False):
        if content_score is not None:
            stars = "â­" * int(content_score) + "â˜†" * (5 - int(content_score))
            st.markdown(f"**Content Quality Score: {stars} ({content_score:.1f}/5)**")
        else:
            st.markdown("**Content Quality Score: N/A**")

        if isinstance(content_analysis_data, dict):
            # Show summary first
            summary = content_analysis_data.get("summary")
            if summary:
                st.markdown(f"**Summary:** {summary}")

            # Show all known aspects
            known_aspects = {
                "clarity": "Clarity",
                "depth_of_information": "Depth of Information",
                "structure_and_flow": "Structure and Flow",
                "value_proposition": "Value Proposition",
                "engagement_factors": "Engagement Factors",
                "originality": "Originality",
                "accuracy": "Accuracy",
                "call_to_action_effectiveness": "Call to Action Effectiveness",
                "script_quality": "Script Quality",
                "presentation_style": "Presentation Style",
                "editing_and_pacing": "Editing and Pacing",
            }
            for key, display_name in known_aspects.items():
                aspect = content_analysis_data.get(key)
                if aspect:
                    if isinstance(aspect, dict):
                        rating = aspect.get("rating")
                        comment = aspect.get("comment") or aspect.get("details", "")
                        if rating and comment:
                            st.markdown(f"**{display_name}:** {rating}. {comment}")
                        elif rating:
                            st.markdown(f"**{display_name}:** {rating}")
                        elif comment:
                            st.markdown(f"**{display_name}:** {comment}")
                    else:
                        st.markdown(f"**{display_name}:** {aspect}")

            # Key topics
            key_topics = content_analysis_data.get("key_topics")
            if key_topics:
                st.markdown("**Key Topics Covered:**")
                if isinstance(key_topics, list):
                    for topic in key_topics:
                        st.markdown(f"    - {topic}")
                else:
                    st.markdown(f"    {key_topics}")

            # Strengths
            strengths = content_analysis_data.get("strengths")
            if strengths:
                st.markdown("**Strengths:**")
                if isinstance(strengths, list):
                    for item in strengths:
                        st.markdown(f"    - {item}")
                else:
                    st.markdown(f"    {strengths}")

            # Weaknesses
            weaknesses = content_analysis_data.get("weaknesses") or content_analysis_data.get("areas_for_improvement")
            if weaknesses:
                st.markdown("**Areas for Improvement / Weaknesses:**")
                if isinstance(weaknesses, list):
                    for item in weaknesses:
                        st.markdown(f"    - {item}")
                else:
                    st.markdown(f"    {weaknesses}")

            # Recommendations
            recommendations = content_analysis_data.get("recommendations")
            if recommendations:
                st.markdown("**Recommendations (Content Specific):**")
                if isinstance(recommendations, list):
                    for rec in recommendations:
                        st.markdown(f"    - {rec}")
                else:
                    st.markdown(f"    {recommendations}")
        else:
            st.warning("Content analysis data is not in the expected format.")

    # Audience Engagement section
    if ai_analysis.get("audience_engagement"):
        st.markdown("## ðŸ‘¥ Audience Engagement")
        content = ai_analysis["audience_engagement"]
        factors = analysis.get("scores", {}).get("factors", {})
        audience_score = None
        try:
            audience_score = float(
                factors.get("engagement_metrics", {}).get("score", None)
            )
            audience_score = min(5.0, audience_score)
        except (TypeError, ValueError):
            audience_score = None
        # Define the engagement display function first
        def display_engagement_content(content, prefix=""):
            if isinstance(content, dict):
                # First try to extract key fields of interest
                important_fields = [
                    "hook_strength", 
                    "storytelling", 
                    "ctas", 
                    "community_potential"
                ]
                recommendations = None
                
                # Special handling for recommendations
                if "recommendations" in content:
                    recommendations = content["recommendations"]
                
                # Display main fields
                for key in important_fields:
                    if key in content and content[key]:
                        key_display = key.replace("_", " ").title()
                        st.markdown(f"**{key_display}:** {content[key]}")
                
                # Display recommendations last
                if recommendations:
                    st.markdown("**Recommendations:**")
                    if isinstance(recommendations, list):
                        for rec in recommendations:
                            st.markdown(f"- {rec}")
                    else:
                        st.markdown(recommendations)
                        
                # Handle any other keys
                for key, value in content.items():
                    if key not in important_fields and key != "recommendations" and key != "score":
                        key_display = key.replace("_", " ").title()
                        if isinstance(value, (dict, list)):
                            st.markdown(f"**{key_display}:**")
                            display_engagement_content(value, prefix + "  ")
                        else:
                            st.markdown(f"**{key_display}:** {value}")
            
            elif isinstance(content, list):
                for item in content:
                    if isinstance(item, (dict, list)):
                        display_engagement_content(item, prefix + "  ")
                    else:
                        st.markdown(f"{prefix}- {item}")
            else:
                st.markdown(f"{prefix}{content}")

        with st.expander("View Audience Engagement Details", expanded=False):
            if audience_score is not None:
                stars = "â­" * int(audience_score) + "â˜†" * (5 - int(audience_score))
                st.markdown(
                    f"**Audience Engagement Score: {stars} ({audience_score:.1f}/5)**"
                )
            else:
                st.markdown("**Audience Engagement Score: N/A**")
            
            # Debug statements removed - UI is now clean
            
            if content:
                # Skip string display that contains raw JSON - only use our formatter
                if isinstance(content, (int, float)):
                    st.markdown(str(content))
                elif isinstance(content, str):
                    # Try to parse JSON from string
                    try:
                        # Find potential JSON in the string
                        import json
                        import re
                        
                        # First check if the entire string is valid JSON
                        json_parsed = False
                        try:
                            json_data = json.loads(content)
                            display_engagement_content(json_data)
                            json_parsed = True
                        except json.JSONDecodeError:
                            pass
                            
                        # Only continue if we haven't successfully parsed JSON yet
                        if not json_parsed:
                            # Look for JSON object pattern within the string
                            json_pattern = r'\{[\s\S]*\}'
                            match = re.search(json_pattern, content)
                            
                            if match:
                                potential_json = match.group(0)
                                try:
                                    json_data = json.loads(potential_json)
                                    display_engagement_content(json_data)
                                    json_parsed = True
                                except json.JSONDecodeError:
                                    pass
                    
                    except Exception as e:
                        st.warning(f"Error parsing Audience Engagement data: {str(e)}")
                    
                    # If we get here and haven't parsed JSON successfully, display the cleaned string
                    if not json_parsed:
                        cleaned = re.sub(r"Audience Engagement \([\-\d.]+/5\)\*\*:?:?\s*", "", content)
                        # Remove "Audience Engagement (3/5)" line that might be in the string
                        cleaned = re.sub(r"Audience Engagement \([\d\.]+/5\)\s*\n", "", cleaned)
                        st.markdown(cleaned)
                elif isinstance(content, (dict, list)):
                    # Display structured data nicely instead of raw JSON
                    display_engagement_content(content)
                else:
                    st.warning("Audience engagement analysis data is not displayable.")
            else:
                st.markdown("No audience engagement analysis available.")

    # Technical Performance section
    if ai_analysis.get("technical_performance"):
        st.markdown("## âš™ï¸ Technical Performance")
        content = ai_analysis["technical_performance"]
        factors = analysis.get("scores", {}).get("factors", {})
        tech_score = None
        try:
            tech_score = float(factors.get("technical_quality", {}).get("score", None))
            tech_score = min(5.0, tech_score)
        except (TypeError, ValueError):
            tech_score = None
        # Define technical content display function first
        def display_technical_content(content, prefix=""):
            if isinstance(content, dict):
                # First try to extract key fields of interest
                important_fields = [
                    "video_quality", 
                    "audio_quality", 
                    "length_appropriateness", 
                    "accessibility"
                ]
                recommendations = None
                
                # Special handling for recommendations
                if "recommendations" in content:
                    recommendations = content["recommendations"]
                
                # Display main fields
                for key in important_fields:
                    if key in content and content[key]:
                        key_display = key.replace("_", " ").title()
                        st.markdown(f"**{key_display}:** {content[key]}")
                
                # Display recommendations last
                if recommendations:
                    st.markdown("**Recommendations:**")
                    if isinstance(recommendations, list):
                        for rec in recommendations:
                            st.markdown(f"- {rec}")
                    else:
                        st.markdown(recommendations)
                        
                # Handle any other keys
                for key, value in content.items():
                    if key not in important_fields and key != "recommendations" and key != "score":
                        key_display = key.replace("_", " ").title()
                        if isinstance(value, (dict, list)):
                            st.markdown(f"**{key_display}:**")
                            display_technical_content(value, prefix + "  ")
                        else:
                            st.markdown(f"**{key_display}:** {value}")
            
            elif isinstance(content, list):
                for item in content:
                    if isinstance(item, (dict, list)):
                        display_technical_content(item, prefix + "  ")
                    else:
                        st.markdown(f"{prefix}- {item}")
            else:
                st.markdown(f"{prefix}{content}")

        with st.expander("View Technical Performance Details", expanded=False):
            if tech_score is not None:
                stars = "â­" * int(tech_score) + "â˜†" * (5 - int(tech_score))
                st.markdown(
                    f"**Technical Performance Score: {stars} ({tech_score:.1f}/5)**"
                )
            else:
                st.markdown("**Technical Performance Score: N/A**")
            
            # Debug statements removed - UI is now clean
            
            if content:
                # Skip string display that contains raw JSON - only use our formatter
                if isinstance(content, (int, float)):
                    st.markdown(str(content))
                elif isinstance(content, str):
                    # Try to parse JSON from string
                    try:
                        # Find potential JSON in the string
                        import json
                        import re
                        
                        # First check if the entire string is valid JSON
                        json_parsed = False
                        try:
                            json_data = json.loads(content)
                            display_technical_content(json_data)
                            json_parsed = True
                        except json.JSONDecodeError:
                            pass
                            
                        # Only continue if we haven't successfully parsed JSON yet
                        if not json_parsed:
                            # Look for JSON object pattern within the string
                            json_pattern = r'\{[\s\S]*\}'
                            match = re.search(json_pattern, content)
                            
                            if match:
                                potential_json = match.group(0)
                                try:
                                    json_data = json.loads(potential_json)
                                    display_technical_content(json_data)
                                    json_parsed = True
                                except json.JSONDecodeError:
                                    pass
                    
                    except Exception as e:
                        st.warning(f"Error parsing Technical Performance data: {str(e)}")
                    
                    # If we get here and haven't parsed JSON successfully, display the cleaned string
                    if not json_parsed:
                        cleaned = re.sub(r"Technical Performance \([\-\d.]+/5\)\*\*:?:?\s*", "", content)
                        # Remove "Technical Performance (3/5)" line that might be in the string
                        cleaned = re.sub(r"Technical Performance \([\d\.]+/5\)\s*\n", "", cleaned)
                        st.markdown(cleaned)
                elif isinstance(content, (dict, list)):
                    # Display structured data nicely instead of raw JSON
                    display_technical_content(content)
                else:
                    st.warning("Technical performance analysis data is not displayable.")
            else:
                st.markdown("No technical performance analysis available.")

    # Display Optimization Recommendations in a separate section
    if "recommendations" in analysis and analysis["recommendations"]:
        recommendations = analysis["recommendations"]
        if (
            "overall_recommendations" in recommendations
            and recommendations["overall_recommendations"]
        ):
            st.markdown("## ðŸ’¡ Optimization Recommendations")

            # Display overall recommendations
            for i, rec in enumerate(recommendations["overall_recommendations"]):
                st.markdown(f"**{i+1}.** {rec}")

            # Factor-specific recommendations
            if "factor_recommendations" in recommendations:
                with st.expander("See detailed recommendations by factor"):
                    for factor_name, factor_data in recommendations[
                        "factor_recommendations"
                    ].items():
                        if (
                            factor_name != "ai_suggestions"
                        ):  # Skip AI suggestions as they're already in overall
                            factor_display_name = factor_name.replace("_", " ").title()
                            st.markdown(
                                f"**{factor_display_name}** ({factor_data.get('description', '')})"
                            )
                            for rec in factor_data.get("recommendations", []):
                                st.markdown(f"- {rec}")

    # Display related videos if available
    if "related_videos" in analysis and analysis["related_videos"]:
        st.subheader("ðŸ” Related Videos")

        # Create columns for related videos
        cols = st.columns(3)

        for i, video in enumerate(
            analysis["related_videos"][:6]
        ):  # Show up to 6 related videos
            with cols[i % 3]:
                # Create a card-like display for each related video
                st.markdown(
                    f"[**{video.get('title', 'Unknown')}**]({video.get('url', '')})"
                )
                # Format view count with commas
                view_count = video.get("view_count", "0")
                try:
                    view_count = f"{int(view_count):,}"
                except (ValueError, TypeError):
                    pass  # Keep original if not convertible to int
                st.caption(
                    f"ðŸ‘ï¸ {view_count} views â€¢ â±ï¸ {video.get('formatted_duration', 'Unknown')}"
                )

                if "thumbnail_url" in video:
                    st.image(video["thumbnail_url"], use_container_width=True)

    # No duplicate sections needed - the recommendations and related videos are already displayed above


def clean_response_text(response, for_chat=True):
    """Extract plain text from a potentially structured response.
    
    Args:
        response: A response that could be plain text, a dict with 'text' key,
                 or a string representation of such a dict
        for_chat: If True, process for chat display (extract text from structures).
                  If False, preserve structured data (for analysis).
                 
    Returns:
        str or dict: Cleaned response - plain text for chat or preserved structure for analysis
    """
    # Don't process structured data if not for chat display
    if not for_chat and isinstance(response, dict):
        print(f"[clean_response_text] Preserving structured data for analysis: {type(response)}")
        return response
    
    # Return as is if None or empty
    if not response:
        return response
        
    # Handle dictionary response for chat display
    if isinstance(response, dict) and "text" in response:
        print(f"[clean_response_text] Extracting text from dict: {response.keys()}")
        return response["text"]
        
    # Handle string representation of dictionary for chat display
    if isinstance(response, str):
        # Check if it looks like a JSON object with a text key
        if response.startswith('{') and response.endswith('}') and '"text"' in response:
            try:
                # import json # Assuming json is imported at the top of the file
                parsed = json.loads(response)
                if isinstance(parsed, dict) and "text" in parsed:
                    print(f"[clean_response_text] Extracted text from JSON string")
                    return parsed["text"]
            except json.JSONDecodeError:
                # Not valid JSON, or JSON doesn't have 'text' key
                print(f"[clean_response_text] Failed to parse as JSON or extract text, trying literal_eval.")
                pass # Fall through to literal_eval or return original

        # Try ast.literal_eval for strings that look like Python dicts/lists
        # (e.g., "{'text': '...'}")
        if response.strip().startswith('{') and response.strip().endswith('}'):
            try:
                # import ast # Assuming ast is imported at the top of the file
                parsed_literal = ast.literal_eval(response)
                if isinstance(parsed_literal, dict) and "text" in parsed_literal:
                    print(f"[clean_response_text] Extracted text using ast.literal_eval from dict-like string.")
                    return parsed_literal["text"]
            except (ValueError, SyntaxError, TypeError) as e:
                # ast.literal_eval failed, it's likely just a plain string
                print(f"[clean_response_text] ast.literal_eval failed ({e}), treating as plain string.")
                pass # Fall through to return original response
    
    # Return original if no transformation needed or possible
    print(f"[clean_response_text] No specific cleaning applied, returning original: {type(response)}")
    return response


def format_numbers_with_commas(text):
    """Format numbers in text with commas for thousands."""
    if not text:
        return text
        
    import re
    
    # Debug the incoming text to understand what we're processing
    print(f"[format_numbers] Processing text: {text[:100]}...")
    
    # Use regex to find and replace numbers after specific labels
    # The patterns are designed to match various formats of views/likes/comments
    def add_commas(match):
        """Add commas to a number match."""
        try:
            prefix = match.group(1)  # The label part ("Views: ", etc.)
            number = match.group(2)  # The number part
            # Strip any existing commas before formatting
            clean_number = number.replace(',', '')
            formatted = f"{int(clean_number):,}"
            # Debug successful formatting
            print(f"[format_numbers] Formatted: {number} -> {formatted}")
            return f"{prefix}{formatted}"
        except (ValueError, TypeError, IndexError) as e:
            # If any error occurs, return the original match
            print(f"[format_numbers] Error formatting: {e}")
            return match.group(0)
    
    # Much more aggressive and comprehensive pattern matching
    # Cover all possible formats we've seen in the chat
    patterns = [
        # Basic formats with various spacing
        (r'(Views:)\s*(\d+)', add_commas),
        (r'(Likes:)\s*(\d+)', add_commas),
        (r'(Comments:)\s*(\d+)', add_commas),
        
        # Bold markdown with various spacing
        (r'(\*\*Views:\*\*)\s*(\d+)', add_commas),
        (r'(\*\*Likes:\*\*)\s*(\d+)', add_commas),
        (r'(\*\*Comments:\*\*)\s*(\d+)', add_commas),
        
        # With explicit space after colon
        (r'(Views: )(\d+)', add_commas),
        (r'(Likes: )(\d+)', add_commas),
        (r'(Comments: )(\d+)', add_commas),
        
        # Bold with explicit space after colon
        (r'(\*\*Views:\*\* )(\d+)', add_commas),
        (r'(\*\*Likes:\*\* )(\d+)', add_commas),
        (r'(\*\*Comments:\*\* )(\d+)', add_commas),
        
        # Handle potential variations in capitalization
        (r'(VIEWS:)\s*(\d+)', add_commas),
        (r'(LIKES:)\s*(\d+)', add_commas),
        (r'(COMMENTS:)\s*(\d+)', add_commas),
        
        # Handle variations with parentheses or brackets
        (r'(Views[^\d]+)(\d+)', add_commas),
        (r'(Likes[^\d]+)(\d+)', add_commas),
        (r'(Comments[^\d]+)(\d+)', add_commas)
    ]
    
    # Apply each pattern and check if any changes were made
    original_text = text
    for pattern, replacement in patterns:
        text = re.sub(pattern, replacement, text)
    
    # Extra safety check: directly target known patterns with fixed position lookups
    for metric in ['Views', 'Likes', 'Comments']:
        # Look for patterns like "Views: 123456" with raw number extraction
        pattern = f"{metric}: (\d+)"
        matches = re.finditer(pattern, text)
        for match in matches:
            try:
                full_match = match.group(0)
                number_part = match.group(1)
                if ',' not in number_part:  # Only format if commas aren't already there
                    formatted_number = f"{int(number_part):,}"
                    replacement = f"{metric}: {formatted_number}"
                    text = text.replace(full_match, replacement)
                    print(f"[format_numbers] Direct replacement: {full_match} -> {replacement}")
            except Exception as e:
                print(f"[format_numbers] Error in direct replacement: {str(e)}")
    
    # Debug if formatting made any changes
    if original_text != text:
        print("[format_numbers] Formatting was applied successfully")
    else:
        print("[format_numbers] No formatting changes were made")
    
    return text

def display_chat():
    """Display the chat history from st.session_state.messages."""
    for i, message in enumerate(st.session_state.get("messages", [])):
        with st.chat_message(message["role"]):
            # Skip special message handling
            if message.get("type") == "thinking_indicator":
                st.markdown(message["content"])
                continue
                
            # Format response for display
            content_to_display = message.get("content", "")
            if isinstance(content_to_display, dict):
                content_to_display = clean_response_text(content_to_display, for_chat=True)
            else:
                content_to_display = clean_response_text(str(content_to_display), for_chat=True)
            
            # GUARANTEED NUMBER FORMATTING: Always format numbers with commas
            # This is critical for consistent display
            message_type = message.get("type", "")
            print(f"[display_chat] Processing message type: {message_type}, content starts with: {str(content_to_display)[:50]}...")
            
            # Apply aggressive number formatting
            original_content = content_to_display
            content_to_display = format_numbers_with_commas(content_to_display)
            
            # If it's a video analysis, force direct replacements for key metrics
            if message_type == "video_analysis":
                # Direct hard-coded replacements as an extra safety measure
                import re
                for metric in ['Views', 'Likes', 'Comments']:
                    pattern = f"\*\*{metric}\*\*: (\d+)"
                    matches = re.finditer(pattern, content_to_display)
                    for match in matches:
                        try:
                            num_str = match.group(1)
                            if ',' not in num_str:  # Only format if commas aren't already there
                                formatted_num = f"{int(num_str):,}"
                                old_text = f"**{metric}**: {num_str}"
                                new_text = f"**{metric}**: {formatted_num}"
                                content_to_display = content_to_display.replace(old_text, new_text)
                                print(f"[display_chat] Forced metric formatting: {old_text} -> {new_text}")
                        except Exception as e:
                            print(f"[display_chat] Error formatting {metric}: {str(e)}")
            
            if content_to_display != original_content:
                print(f"[display_chat] Successfully formatted numbers in message")
            
            # Display the formatted content
            st.markdown(content_to_display)


def save_current_conversation():
    """Save the current state of the active chat to the conversation history."""
    # Check if saving should be skipped for this chat (important for New Chat flow)
    if st.session_state.get("skip_save_for_current_chat", False):
        logger.info("Skipping save due to skip_save_for_current_chat flag.")
        # Reset the flag after using it
        st.session_state.skip_save_for_current_chat = False
        return
        
    current_chat_id = st.session_state.get("current_chat_id")
    if not current_chat_id:
        logger.warning("save_current_conversation called without current_chat_id.")
        return

    current_messages = st.session_state.get("messages", [])
    current_analysis_data = st.session_state.get("current_analysis")
    current_title = st.session_state.get("current_chat_title", f"Chat {current_chat_id[:8]}")
    current_video_url = st.session_state.get("current_video_url")

    # Only save if there's more than the initial assistant message OR if there's analysis data
    # The initial message is from the assistant.
    has_meaningful_content = len(current_messages) > 1 or current_analysis_data is not None

    if not has_meaningful_content:
        logger.info(f"Skipping save for chat {current_chat_id} as it has no meaningful content.")
        return

    current_chat_data = {
        "id": current_chat_id,
        "title": current_title,
        "messages": sanitize_for_json(current_messages),
        "analysis": sanitize_for_json(current_analysis_data),
        "video_url": current_video_url,  # Store video URL with the conversation
        "timestamp": datetime.now().isoformat(),
    }

    history = st.session_state.get("conversation_history", [])
    found_in_history = False
    for i, conv_in_history in enumerate(history):
        if conv_in_history.get("id") == current_chat_id:
            history[i] = current_chat_data
            found_in_history = True
            logger.info(f"Updated existing chat in history: {current_chat_id}")
            break
    
    if not found_in_history:
        history.insert(0, current_chat_data) # Prepend to show most recent first
        logger.info(f"Added new chat to history: {current_chat_id}")

    st.session_state.conversation_history = history[:MAX_HISTORY_ITEMS]
    persist_chat_history(st.session_state.conversation_history)


def generate_contextual_response(prompt: str, analysis: Dict[str, Any]) -> str:
    """
    Generate a contextual response based on user input and video analysis data.

    Args:
        prompt: User's query or prompt
        analysis: Dictionary containing video analysis data

    Returns:
        A markdown-formatted response to the user's query
    """
    # Debug output to console only (not visible to users)
    print("\n" + "=" * 50)
    print(f"generate_contextual_response called for prompt: {prompt}")
    print(f"Analysis data available: {list(analysis.keys()) if analysis else 'None'}")
    print("=" * 50)

    # Ensure we have valid analysis data
    if not analysis or not isinstance(analysis, dict):
        return "I don't have enough information about the video to answer that question. Please try analyzing a video first."

    # Extract metadata and analysis data for easier access
    metadata = analysis.get("metadata", {})
    analysis_data = analysis.get("analysis", {})
    scores = analysis.get("scores", {})
    recommendations = analysis.get("recommendations", {})

    # Safely get thumbnail_analysis from the analysis data
    thumbnail_analysis = analysis.get("thumbnail_analysis", {})

    # Use Gemini to generate a comprehensive response
    # Helper function to be run in a thread
    def _call_gemini_and_extract_text(gemini_client_instance, current_comprehensive_prompt, current_generation_config, original_timestamp_for_prompt_id):
        # This function encapsulates the original Gemini call and response processing logic.
        # It's designed to be executed in a separate thread.
        try:
            print(f"THREAD: Sending comprehensive prompt to Gemini with Response ID: {original_timestamp_for_prompt_id}")
            # Original call to Gemini (from line 2004)
            response_obj = gemini_client_instance.generate_content(
                current_comprehensive_prompt, generation_config=current_generation_config
            )

            # Original text extraction logic (lines 2009-2031 of original file)
            try:
                if hasattr(response_obj, "text"):
                    response_text = response_obj.text
                elif hasattr(response_obj, "parts") and len(response_obj.parts) > 0:
                    response_text = response_obj.parts[0].text
                elif hasattr(response_obj, "candidates") and len(response_obj.candidates) > 0:
                    candidate = response_obj.candidates[0]
                    if hasattr(candidate, "content") and hasattr(candidate.content, "parts") and len(candidate.content.parts) > 0:
                        response_text = candidate.content.parts[0].text
                    else:
                        response_text = str(candidate)
                else:
                    response_text = str(response_obj)

                if not response_text or len(response_text.strip()) == 0:
                    response_text = "I couldn't generate a specific response to your question. Please try rephrasing or asking something else about this video."
            except Exception as e_extract:
                print(f"THREAD: Error extracting text from Gemini response: {str(e_extract)}")
                # Raise an error to be caught by future.result() in the main thread
                raise RuntimeError(f"Error extracting text from Gemini response: {str(e_extract)}") from e_extract

            # Original debug logging (lines 2041-2042)
            print(f"THREAD: Received response from Gemini with length: {len(response_text)}")
            print(f"THREAD: Response preview: {response_text[:100]}...")
            
            # Original enhanced parsing (lines 2050-2061)
            print(f"THREAD: Response before cleaning: {response_text[:100]}")
            if isinstance(response_text, str):
                if response_text.strip().startswith('{') and '"text"' in response_text:
                    try:
                        # Ensure json is available (it's imported at the top of streamlit_app.py)
                        parsed_json = json.loads(response_text)
                        if isinstance(parsed_json, dict) and 'text' in parsed_json:
                            response_text = parsed_json['text']
                            print("THREAD: Extracted text from JSON string")
                    except json.JSONDecodeError:
                        print("THREAD: Failed to parse as JSON, using as-is")
            elif isinstance(response_text, dict) and 'text' in response_text:
                response_text = response_text['text']
                print("THREAD: Extracted text from dictionary response")
            
            print(f"THREAD: Response after cleaning: {response_text[:100]}")
            return response_text # Return the final cleaned text
        except Exception as e_main_gemini_call:
            # If Gemini call itself fails (original lines 2064-2068)
            print(f"THREAD: Error generating response with Gemini: {str(e_main_gemini_call)}")
            # Raise an exception to be caught by future.result() in the main thread
            raise RuntimeError(f"Error generating response with Gemini: {str(e_main_gemini_call)}") from e_main_gemini_call

    # New logic using ThreadPoolExecutor
    prompt_key = prompt # Use the original user prompt as the key for the future
    
    # Create timestamp for tracking
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
    
    # Create the comprehensive prompt for Gemini API
    # Include video URL in the prompt for better context
    video_url = st.session_state.get('current_video_url', 'Unknown')
    print(f"[DEBUG_TRACE] Including video URL in prompt: {video_url}")
    
    comprehensive_prompt = f"""
    # YOUTUBE VIDEO ASSISTANT - RESPONSE GENERATION
    Response ID: {timestamp}_query
    Video URL: {video_url}

    ## USER QUERY
    {prompt}

    ## VIDEO INFORMATION
    Video ID: {metadata.get('video_id', 'Unknown')}
    Title: {metadata.get('title', 'Unknown')}
    Channel: {metadata.get('channel_title', 'Unknown')}
    Duration: {metadata.get('duration', 'Unknown')}
    Views: {metadata.get('view_count', 'Unknown')}
    Likes: {metadata.get('like_count', 'Unknown')}
    Comments: {metadata.get('comment_count', 'Unknown')}
    Publication Date: {metadata.get('published_at', 'Unknown')}
    
    ## ANALYSIS
    Title Analysis: {analysis_data.get('title_analysis', {})}
    Thumbnail Analysis: {thumbnail_analysis}
    Content Quality Analysis: {analysis_data.get('content_quality_analysis', {})}
    Technical Performance Analysis: {analysis_data.get('technical_analysis', {})}
    Audience Engagement Analysis: {analysis_data.get('engagement_analysis', {})}
    SEO Analysis: {analysis_data.get('seo_analysis', {})}
    
    ## SCORES
    Overall Score: {scores.get('overall_score', 'Unknown')}
    Title Analysis Score: {scores.get('factors', {}).get('hook_quality', {}).get('title_score', 'Unknown')}
    Thumbnail Analysis Score: {scores.get('factors', {}).get('hook_quality', {}).get('thumbnail_score', 'Unknown')}
    Hook Quality: {scores.get('factors', {}).get('hook_quality', {}).get('score', 'Unknown')}
    Content Quality: {scores.get('factors', {}).get('content_quality', {}).get('score', 'Unknown')}
    Technical Performance: {scores.get('factors', {}).get('technical_quality', {}).get('score', 'Unknown')}
    Audience Engagement: {scores.get('factors', {}).get('engagement_metrics', {}).get('score', 'Unknown')}
    SEO Optimization: {scores.get('factors', {}).get('seo_optimization', {}).get('score', 'Unknown')}
    
    ## RECOMMENDATIONS
    {recommendations}

    ## VIDEO DESCRIPTION
    {metadata.get('description', 'Not available')}
    
    ## TASK
    Using the video information and analysis provided above, answer the user's query in a helpful, accurate, and engaging way.
    Provide specific information from the analysis and video details.
    
    If the user's query cannot be fully answered with the analysis data provided:
    1. Use your knowledge about the video content based on the Video URL
    2. Clearly indicate when you're using information beyond what's in the analysis report
    3. If you don't know and can't determine from the URL, state that clearly
    
    DO NOT include markdown code blocks in your response.
    Format your response naturally, as if you are having a conversation.
    When recommending improvements, be constructive and positive.
    """
    
    # Define generation config for consistent response
    generation_config = {
        "temperature": 0.7,
        "top_p": 0.8,
        "top_k": 40,
        "max_output_tokens": 2048,
    }
    
    gemini_client_to_use = st.session_state.gemini_client

    if prompt_key in st.session_state.gemini_futures:
        future = st.session_state.gemini_futures[prompt_key]
        if future.done():
            try:
                response_text = future.result() # This will re-raise exceptions from the thread
                del st.session_state.gemini_futures[prompt_key] # Clean up the future
                # Log success to console only
                print(f"ASYNC_RESULT: Received response from Gemini with length: {len(response_text)}")
                print(f"ASYNC_RESULT: Response preview: {response_text[:100]}...")
                return response_text
            except Exception as e:
                del st.session_state.gemini_futures[prompt_key] # Ensure cleanup on error
                print(f"ASYNC_ERROR: Error getting result from Gemini future: {str(e)}", exc_info=True)
                # Return the error message similar to the original error handling (lines 2066-2068)
                return f"I encountered an error processing your request (async). Error details: {str(e)}"
        else:
            print(f"Gemini response for '{prompt_key}' is still pending.")
            return "PENDING_RESPONSE" # Special status to indicate processing
    else:
        print(f"Submitting Gemini call for '{prompt_key}' to thread pool.")
        
        # 'timestamp' (original line 1938) is used in 'comprehensive_prompt'.
        # 'comprehensive_prompt' and 'generation_config' are already defined in the outer scope
        # of generate_contextual_response, before the original 'try' block.
        future = st.session_state.thread_executor.submit(
            _call_gemini_and_extract_text,
            gemini_client_to_use,
            comprehensive_prompt, 
            generation_config,
            timestamp # This is the original timestamp from line 1938, used in the prompt's Response ID
        )
        st.session_state.gemini_futures[prompt_key] = future
        return "PENDING_RESPONSE" # Special status to indicate processing


def process_user_input(new_prompt):
    """Process the user's input after it's been submitted."""
    if not new_prompt:
        # Return early if no input provided
        return
        
    print(f"[DEBUG_TRACE] Processing new prompt: '{new_prompt}'")
    
    # Initialize user_message at the beginning to avoid undefined variable errors
    # This ensures it's available in all code paths
    user_message = {"role": "user", "content": new_prompt}
    
    # Important: DON'T append user message immediately for YouTube URLs with questions
    # We'll handle that specially if needed
    
    # Check for YouTube URLs
    if "youtube.com" in new_prompt or "youtu.be" in new_prompt:
        # Extract the YouTube URL from the prompt
        url_pattern = re.compile(r'(https?://(?:www\.)?(?:youtube\.com|youtu\.be)[^\s]+)')
        url_match = url_pattern.search(new_prompt)
        youtube_url = url_match.group(0) if url_match else new_prompt.strip()
        
        # Check if there's additional text besides the URL
        remaining_text = new_prompt.replace(youtube_url, '').strip()
        
        if remaining_text:  # There's additional text/question alongside the URL
            print(f"[DEBUG_TRACE] URL with additional text detected: URL={youtube_url}, Question={remaining_text}")
            
            # Check if we already have analysis for this URL
            already_analyzed = False
            
            # Check if current_video_url matches
            if "current_video_url" in st.session_state and st.session_state.current_video_url == youtube_url:
                already_analyzed = "current_analysis" in st.session_state and st.session_state.current_analysis
            
            # If not current, check conversation history
            if not already_analyzed:
                for chat in st.session_state.get("conversation_history", []):
                    if chat.get("video_url") == youtube_url and chat.get("analysis"):
                        print(f"[DEBUG_TRACE] Found existing analysis for URL in history")
                        st.session_state.current_video_url = youtube_url
                        st.session_state.current_analysis = copy.deepcopy(chat.get("analysis"))
                        already_analyzed = True
                        break
                
            if already_analyzed:
                print(f"[DEBUG_TRACE] Using existing analysis for URL: {youtube_url}")
                
                # IMPORTANT: Update session state first
                st.session_state.current_video_url = youtube_url
                
                # Remove the original user message (which contained URL + question)
                st.session_state.messages.pop()
                
                # Create user message with just the question and proper metadata
                user_message = {
                    "role": "user", 
                    "content": remaining_text, 
                    "video_url": youtube_url
                }
                st.session_state.messages.append(user_message)
                
                # Set up for response generation
                st.session_state.current_processing_prompt = remaining_text
                st.session_state.is_generating_response = True
                
                # Add thinking indicator with video context
                thinking_msg = {
                    "role": "assistant", 
                    "content": "ðŸ¤” Thinking...", 
                    "type": "thinking_indicator", 
                    "video_url": youtube_url
                }
                st.session_state.messages.append(thinking_msg)
                
                # Force save first to ensure context is maintained
                save_current_conversation()
                
                # Set a special flag that we're coming from a URL+question scenario
                # This flag will survive the rerun and tell the main flow not to analyze the video again
                st.session_state.url_question_answered = True
                
                # Now force a rerun to trigger the response generation part
                print(f"[DEBUG_TRACE] Forcing rerun for question: {remaining_text}")
                st.rerun()
            else:
                print(f"[DEBUG_TRACE] No existing analysis found, analyzing video: {youtube_url}")
                analyze_video(youtube_url)
                # After analysis completes, we'll need to handle the question
                st.session_state.pending_question = remaining_text
        else:
            # Just a URL with no additional text - but first check if we already analyzed it before
            is_already_analyzed = False
            
            # Check if current_video_url matches
            if "current_video_url" in st.session_state and st.session_state.current_video_url == new_prompt:
                is_already_analyzed = "current_analysis" in st.session_state and st.session_state.current_analysis
            
            # If not current, check conversation history
            if not is_already_analyzed:
                for chat in st.session_state.get("conversation_history", []):
                    if chat.get("video_url") == new_prompt and chat.get("analysis"):
                        st.session_state.current_video_url = new_prompt
                        st.session_state.current_analysis = copy.deepcopy(chat.get("analysis"))
                        is_already_analyzed = True
                        print(f"[DEBUG_TRACE] Found existing analysis for URL in history: {new_prompt}")
                        break
            
            # Now add user message to chat history with video URL metadata
            user_message = {"role": "user", "content": new_prompt}
            if "current_video_url" in st.session_state:
                user_message["video_url"] = st.session_state.current_video_url
            st.session_state.messages.append(user_message)
            
            if is_already_analyzed:
                print(f"[DEBUG_TRACE] URL already analyzed, skipping re-analysis: {new_prompt}")
                # Set up for response generation - no need to reanalyze
                st.session_state.current_processing_prompt = "Tell me about this video"
                st.session_state.is_generating_response = True
                
                # Add thinking indicator with video context
                thinking_msg = {
                    "role": "assistant", 
                    "content": "ðŸ¤” Thinking...", 
                    "type": "thinking_indicator", 
                    "video_url": new_prompt
                }
                st.session_state.messages.append(thinking_msg)
                
                # Force save first to ensure context is maintained
                save_current_conversation()
                
                # Now force a rerun to trigger the response generation part
                print(f"[DEBUG_TRACE] Forcing rerun to generate response for already analyzed URL")
                st.rerun()
            else:
                # New URL that needs analysis
                print(f"[DEBUG_TRACE] Prompt is a URL without additional text. Calling analyze_video for: {new_prompt}")
                analyze_video(new_prompt)
                # analyze_video should handle its own state, messages, and reruns.
                # The save_current_conversation and rerun below will catch any state changes it makes if it doesn't rerun itself.
    elif "current_analysis" in st.session_state and st.session_state.current_analysis:
        print("[DEBUG_TRACE] Prompt is a question and current_analysis IS available.")
            
        # Ensure video context is tracked and attached to the message
        video_url = st.session_state.get('current_video_url')
        if video_url:
            print(f"[DEBUG_TRACE] Video context available: {video_url}")
            user_message["video_url"] = video_url
        else:
            # Try to reconstruct video URL from analysis data if missing
            if isinstance(st.session_state.current_analysis, dict) and 'video_id' in st.session_state.current_analysis:
                video_id = st.session_state.current_analysis.get('video_id')
                if video_id:
                    reconstructed_url = f"https://www.youtube.com/watch?v={video_id}"
                    st.session_state.current_video_url = reconstructed_url
                    print(f"[DEBUG_TRACE] Reconstructed video URL from ID: {reconstructed_url}")
                    user_message["video_url"] = reconstructed_url
            
        # Add the user message if not already added
        if len(st.session_state.messages) == 0 or st.session_state.messages[-1].get("role") != "user" or st.session_state.messages[-1].get("content") != new_prompt:
            st.session_state.messages.append(user_message)
            
        # Set up for response generation
        st.session_state.current_processing_prompt = new_prompt
        st.session_state.is_generating_response = True
        
        # Add thinking indicator with video context
        thinking_msg = {"role": "assistant", "content": "ðŸ¤” Thinking...", "type": "thinking_indicator"}
        if st.session_state.get('current_video_url'):
            thinking_msg["video_url"] = st.session_state.get('current_video_url')
            
        st.session_state.messages.append(thinking_msg)
        print("[DEBUG_TRACE] Set flags for response generation, appended 'Thinking...'. Will save and rerun.")
        
        # Force save and rerun to show the thinking indicator
        save_current_conversation()
        st.rerun()
    else:  # Question, but no current_analysis
        print("[DEBUG_TRACE] Prompt is a question but current_analysis IS NOT available.")
        
        # Try to restore analysis from history using video URL
        restored = False
        video_url = None
        
        # Check if we have a video URL in the current session state
        if "current_video_url" in st.session_state and st.session_state.current_video_url:
            video_url = st.session_state.current_video_url
            print(f"[DEBUG_TRACE] Found current_video_url in session: {video_url}")
        else:
            # Try to find the most recent video URL from the conversation history
            for msg in reversed(st.session_state.messages):
                if msg.get("video_url"):
                    video_url = msg["video_url"]
                    print(f"[DEBUG_TRACE] Found video_url in message history: {video_url}")
                    break
        
        if video_url:
            # Try to find the analysis in conversation history
            for chat in st.session_state.get("conversation_history", []):
                if chat.get("video_url") == video_url and chat.get("analysis"):
                    st.session_state.current_video_url = video_url
                    st.session_state.current_analysis = copy.deepcopy(chat.get("analysis"))
                    restored = True
                    print(f"[DEBUG_TRACE] Restored analysis from history for URL: {video_url}")
                    break
        
        if restored:
            # Successfully restored video context and analysis
            print("[DEBUG_TRACE] Successfully restored video context and analysis")
            
            # Now handle as if analysis was available all along
            if "current_video_url" in st.session_state:
                user_message["video_url"] = st.session_state.current_video_url
            
            # Append user message if not already added
            if not st.session_state.messages or st.session_state.messages[-1]["role"] != "user" or st.session_state.messages[-1]["content"] != new_prompt:
                st.session_state.messages.append(user_message)
            
            # Set up for response generation
            st.session_state.current_processing_prompt = new_prompt
            st.session_state.is_generating_response = True
            
            # Add thinking indicator with video context
            thinking_msg = {"role": "assistant", "content": "ðŸ¤” Thinking...", "type": "thinking_indicator"}
            if "current_video_url" in st.session_state:
                thinking_msg["video_url"] = st.session_state.current_video_url
            
            st.session_state.messages.append(thinking_msg)
            print("[DEBUG_TRACE] Set flags for response generation with restored context. Will save and rerun.")
            
            # Force save and rerun to show the thinking indicator
            save_current_conversation()
            st.rerun()
        else:
            # Could not restore video context
            print("[DEBUG_TRACE] Could not restore video context or analysis")
            
            # Add user message to history if not already added
            if not st.session_state.messages or st.session_state.messages[-1]["role"] != "user" or st.session_state.messages[-1]["content"] != new_prompt:
                st.session_state.messages.append(user_message)
            
            # Inform user they need to provide a video URL first
            no_analysis_response = "I can help analyze YouTube videos. Please provide a YouTube URL first, then ask your question."
            st.session_state.messages.append({
                "role": "assistant",
                "content": no_analysis_response,
                "type": "info"
            })
            logger.debug(f"[DEBUG_TRACE] Appended 'no analysis' message: {no_analysis_response[:100]}...")
            
            # Save and rerun
            save_current_conversation()
            print(f"[DEBUG_TRACE] First pass: Conversation saved. Rerunning. Messages count: {len(st.session_state.messages)}")
            st.rerun()

def handle_user_input():
    """Handle user input and generate responses."""
    # This function no longer handles new user inputs from the chat input box
    # It only manages the ongoing response generation process
    # New inputs are now handled directly in the main function
    
    # Check if we're handling a follow-up question to an already analyzed URL
    if st.session_state.get("url_question_answered", False):
        print("[DEBUG_TRACE] URL+question flag detected. Bypassing video analysis and proceeding to answer")
        # Clear the flag so it doesn't affect future interactions
        st.session_state.url_question_answered = False
        
    # Part 1: Check for and handle ongoing response generation
    if st.session_state.get("is_generating_response", False) and st.session_state.get("current_processing_prompt"):
        print("[DEBUG_TRACE] Second pass: is_generating_response is True and current_processing_prompt exists.")
        prompt_to_process = st.session_state.current_processing_prompt
        
        response_content = None
        try:
            print(f"[DEBUG_TRACE] Attempting to call generate_contextual_response for: {prompt_to_process}")
            if not st.session_state.current_analysis:
                print("[ERROR_TRACE] current_analysis is missing during second pass of response generation. Aborting response.")
                # Pop the 'Thinking...' message first, if it exists as the last message
                if st.session_state.messages and st.session_state.messages[-1].get("type") == "thinking_indicator":
                    st.session_state.messages.pop()
                    print("[DEBUG_TRACE] Popped 'Thinking...' message before appending error.")
                
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": "An issue occurred. Could not retrieve video analysis to generate response. Please try re-analyzing the video or asking a new question.", 
                    "type": "error"
                })
                st.session_state.is_generating_response = False # Reset flags
                st.session_state.current_processing_prompt = None
                save_current_conversation()
                print("[DEBUG_TRACE] Second pass: Error due to missing analysis. Conversation saved. Rerunning.")
                st.rerun()
                return # Exit after handling the error

            analysis_data = st.session_state.current_analysis
            response_content = generate_contextual_response(prompt_to_process, analysis_data)
            print(f"[DEBUG_TRACE] Raw response from generate_contextual_response: {str(response_content)[:200]}...")

            if response_content == "PENDING_RESPONSE":
                print("[DEBUG_TRACE] Second pass: Response is PENDING. Rerunning to check later.")
                # The 'Thinking...' message is already displayed via display_chat and current_processing_prompt.
                # No need to change current_processing_prompt or is_generating_response flags here.
                # No need to save conversation yet.
                st.rerun() # Trigger a rerun to re-check the future status
                return     # Exit this execution of handle_user_input
            
            st.session_state.last_gemini_response = response_content # Store actual response if not pending
        except Exception as e:
            print(f"[DEBUG_TRACE] Error during generate_contextual_response: {str(e)}")
            response_content = f"Error generating response: {str(e)}" # This will be cleaned
        
        cleaned_response = ""
        if response_content:
            print(f"[DEBUG_TRACE] Raw response before cleaning: {str(response_content)[:200]}...")
            cleaned_response = clean_response_text(response_content, for_chat=True)
            print(f"[DEBUG_TRACE] Response after cleaning: {str(cleaned_response)[:100]}...")
        else:
            print("[DEBUG_TRACE] No response_content, using default error message.")
            cleaned_response = "Sorry, I couldn't generate a response at this time."

        # Pop the 'Thinking...' message if it's the last one
        if st.session_state.messages and st.session_state.messages[-1].get("type") == "thinking_indicator":
            st.session_state.messages.pop()
            print("[DEBUG_TRACE] Popped 'Thinking...' message.")
        
        # Add video context to the response message if available
        response_message = {
            "role": "assistant", 
            "content": cleaned_response, 
            "type": "contextual_response"
        }
        
        # Attach video URL to the response for context tracking
        video_url = st.session_state.get('current_video_url')
        if video_url:
            response_message['video_url'] = video_url
            print(f"[DEBUG_TRACE] Added video URL to response: {video_url}")
            
        st.session_state.messages.append(response_message)
        logger.debug(f"[DEBUG_TRACE] Appended final assistant message: {cleaned_response[:100]}...")
        
        st.session_state.is_generating_response = False
        st.session_state.current_processing_prompt = None
        print("[DEBUG_TRACE] Reset is_generating_response and current_processing_prompt.")

        save_current_conversation()
        print(f"[DEBUG_TRACE] Second pass: Conversation saved. Rerunning. Messages count: {len(st.session_state.messages)}")
        st.rerun()
        return # Exit after handling the ongoing response generation

    # Part 2: Handle new user input from chat_input (first pass)
    if st.session_state.get("just_created_new_chat", False):
        st.session_state.just_created_new_chat = False # Consume the flag
        print("[DEBUG_TRACE] 'just_created_new_chat' is True. Continuing to render input box but will ignore any carried-over input.")
        # Instead of returning early, we'll continue to render the input box
        # but we'll ignore any inputs that might have carried over
    
    # This functionality has been moved to the main function
    # DO NOT process new prompts here to avoid duplicate chat inputs
    if False:  # This condition ensures this code never runs
        print(f"[DEBUG_TRACE] This code block is disabled to prevent duplicate input boxes")
        
        # The following code is kept for reference but never executes
        user_message = {"role": "user", "content": "example"}
        
        # For follow-up questions, preserve video context from session state
        if "current_video_url" in st.session_state and st.session_state.current_video_url and not ("youtube.com" in new_prompt or "youtu.be" in new_prompt):
            print(f"[DEBUG_TRACE] Adding existing video context to message: {st.session_state.current_video_url}")
            user_message["video_url"] = st.session_state.current_video_url
        
        if "youtube.com" in new_prompt or "youtu.be" in new_prompt:
            # Check for our special flag that indicates we've already handled this URL+question
            if st.session_state.get("url_question_answered"):
                print(f"[DEBUG_TRACE] Found url_question_answered flag. Skipping re-analysis and proceeding to answer the question.")
                # Clear the flag as we're handling it now
                st.session_state.url_question_answered = False
                # The message is already in session state from the previous step, so just continue below
                # The current_video_url and current_analysis are already set
            else:
                # Track video URL in session state for context persistence
                print(f"[DEBUG_TRACE] Prompt contains URL. Setting current_video_url and analyzing...")
                st.session_state.current_video_url = new_prompt
                user_message["video_url"] = new_prompt  # Add to message metadata
                
                # Append message and analyze
                st.session_state.messages.append(user_message)
                analyze_video(new_prompt) 
                # analyze_video should handle its own state, messages, and reruns.
                # The save_current_conversation and rerun below will catch any state changes if needed.
        elif "current_analysis" in st.session_state and st.session_state.current_analysis:
            print("[DEBUG_TRACE] Prompt is a question and current_analysis IS available.")
            
            # Ensure video context is tracked properly
            if "current_video_url" in st.session_state and st.session_state.current_video_url:
                print(f"[DEBUG_TRACE] Video context available: {st.session_state.current_video_url}")
            else:
                # Try to reconstruct video URL from analysis if missing
                if isinstance(st.session_state.current_analysis, dict) and "video_id" in st.session_state.current_analysis:
                    video_id = st.session_state.current_analysis.get("video_id")
                    if video_id:
                        reconstructed_url = f"https://www.youtube.com/watch?v={video_id}"
                        st.session_state.current_video_url = reconstructed_url
                        print(f"[DEBUG_TRACE] Reconstructed video URL from analysis: {reconstructed_url}")
            
            # Add the user message with video context if available
            if "current_video_url" in st.session_state and st.session_state.current_video_url:
                user_message["video_url"] = st.session_state.current_video_url
            
            # Append user message if not added yet
            if not st.session_state.messages or st.session_state.messages[-1]["role"] != "user" or st.session_state.messages[-1]["content"] != new_prompt:
                st.session_state.messages.append(user_message)
            
            # Set up for response generation
            st.session_state.current_processing_prompt = new_prompt
            st.session_state.is_generating_response = True
            
            # Add thinking indicator with video context
            thinking_msg = {"role": "assistant", "content": "ðŸ¤” Thinking...", "type": "thinking_indicator"}
            if "current_video_url" in st.session_state and st.session_state.current_video_url:
                thinking_msg["video_url"] = st.session_state.current_video_url
            
            st.session_state.messages.append(thinking_msg)
            print("[DEBUG_TRACE] Set flags for response generation, appended 'Thinking...'. Will save and rerun.")
        else: # Question, but no current_analysis
            print("[DEBUG_TRACE] Prompt is a question but current_analysis IS NOT available.")
            no_analysis_response = "No current analysis. Please provide a YouTube URL first so I can answer questions about it."
            st.session_state.messages.append(
                {"role": "assistant", "content": no_analysis_response, "type": "info"}
            )
            logger.debug(f"[DEBUG_TRACE] Appended 'no analysis' message: {no_analysis_response[:100]}...")

        # Common save and rerun for all new prompt scenarios.
        save_current_conversation()
        print(f"[DEBUG_TRACE] First pass: Conversation saved. Rerunning. Messages count: {len(st.session_state.messages)}")
        st.rerun()
    else:
        # This else corresponds to `if new_prompt := st.chat_input(...)`
        # It means no new input was submitted in this specific script run.
        # This is normal during the "second pass" after 'Thinking...' is shown,
        # as the script reruns and `st.chat_input` returns None.
        # The logic in "Part 1" handles the ongoing response generation.
        print("[DEBUG_TRACE] No new prompt received from st.chat_input (normal for second pass or no interaction).")


def analyze_video(video_url: str):
    """
    Analyze a YouTube video and display results.

    Args:
        video_url (str): URL of the YouTube video to analyze
    """
    # First check if this video has already been analyzed
    already_analyzed = False
    
    # First check current session state
    if "current_video_url" in st.session_state and "current_analysis" in st.session_state and st.session_state.current_analysis:
        if st.session_state.current_video_url == video_url:
            already_analyzed = True
            print(f"[DEBUG_TRACE] Video already analyzed in current session, skipping re-analysis: {video_url}")
    
    # Then check conversation history if not found in current session
    if not already_analyzed and "conversation_history" in st.session_state:
        for chat in st.session_state.conversation_history:
            # Check chat video URL
            if chat.get("video_url") == video_url and chat.get("analysis"):
                already_analyzed = True
                st.session_state.current_video_url = video_url
                st.session_state.current_analysis = copy.deepcopy(chat.get("analysis"))
                print(f"[DEBUG_TRACE] Found existing analysis in chat history, using that instead: {video_url}")
                break
            
            # Also check individual messages for video URLs
            if not already_analyzed and chat.get("messages"):
                for msg in chat.get("messages", []):
                    if msg.get("video_url") == video_url and chat.get("analysis"):
                        already_analyzed = True
                        st.session_state.current_video_url = video_url
                        st.session_state.current_analysis = copy.deepcopy(chat.get("analysis"))
                        print(f"[DEBUG_TRACE] Found existing analysis in message history, using that instead: {video_url}")
                        break
    
    # If we found existing analysis, handle any pending questions and skip re-analyzing
    if already_analyzed:
        # If there's a pending question, handle it now
        if "pending_question" in st.session_state and st.session_state.pending_question:
            question = st.session_state.pending_question
            # Clear the pending question
            st.session_state.pending_question = None
            print(f"[DEBUG_TRACE] Processing pending question: {question}")
            
            # Add the question as a separate user message
            st.session_state.messages.append({
                "role": "user", 
                "content": question,
                "video_url": video_url
            })
            
            # Set up for response generation
            st.session_state.current_processing_prompt = question
            st.session_state.is_generating_response = True
            
            # Add thinking indicator with video context
            thinking_msg = {
                "role": "assistant", 
                "content": "ðŸ¤” Thinking...", 
                "type": "thinking_indicator",
                "video_url": video_url
            }
            st.session_state.messages.append(thinking_msg)
            
            # Save conversation and rerun to trigger response generation
            save_current_conversation()
            st.rerun()
        return  # Skip analysis if video already analyzed
    
    with st.chat_message("assistant"):
        with st.spinner("ðŸ” Analyzing video..."):
            try:
                # Step 1: Analyze the video using our VideoAnalyzer
                st.text("Step 1/3: Fetching video data and analyzing content...")
                analysis_result = st.session_state.analyzer.analyze_video(
                    video_url, include_related=True, include_thumbnail=True
                )

                # Check for errors
                if "error" in analysis_result:
                    error_msg = f"Error analyzing video: {analysis_result['error']}"
                    st.error(error_msg)
                    st.session_state.messages.append(
                        {
                            "role": "assistant",
                            "content": f"âŒ {error_msg}",
                            "video_url": video_url,
                            "type": "error",
                        }
                    )
                    return

                # Step 2: Score the video
                st.text("Step 2/3: Calculating performance scores...")
                score_result = st.session_state.scoring_engine.score_video(
                    analysis_result["metadata"], analysis_result["analysis"]
                )

                # Step 3: Generate recommendations
                st.text("Step 3/3: Generating optimization recommendations...")
                recommendation_result = (
                    st.session_state.recommendation_engine.generate_recommendations(
                        analysis_result["metadata"],
                        analysis_result["analysis"],
                        score_result,
                    )
                )

                # Combine all results
                complete_analysis = {
                    "video_id": analysis_result["video_id"],
                    "video_url": video_url,  # Store the original URL for context preservation
                    "metadata": analysis_result["metadata"],
                    "analysis": analysis_result["analysis"],
                    "scores": score_result,
                    "recommendations": recommendation_result,
                }

                # Add thumbnail if available
                if "thumbnail" in analysis_result:
                    complete_analysis["thumbnail"] = analysis_result["thumbnail"]

                # Add title analysis if available
                if "title_analysis" in analysis_result:
                    complete_analysis["title_analysis"] = analysis_result[
                        "title_analysis"
                    ]
                    print("Added title_analysis to complete_analysis")

                # Add thumbnail analysis if available
                if "thumbnail_analysis" in analysis_result:
                    complete_analysis["thumbnail_analysis"] = analysis_result[
                        "thumbnail_analysis"
                    ]
                    print("Added thumbnail_analysis to complete_analysis")

                # Add related videos if available
                if "related_videos" in analysis_result:
                    complete_analysis["related_videos"] = analysis_result[
                        "related_videos"
                    ]

                # Debug the analysis result structure
                print("Analysis result keys:", analysis_result.keys())
                if "thumbnail" in analysis_result:
                    print("Thumbnail data:", analysis_result["thumbnail"])
                if "thumbnail_analysis" in analysis_result:
                    print("Thumbnail analysis available:", True)

                # Store the complete analysis in session state for both display and contextual responses
                # Make sure we don't accidentally clean the structured data
                print(f"Storing analysis with type: {type(complete_analysis)} and keys: {complete_analysis.keys() if hasattr(complete_analysis, 'keys') else 'no keys'}")
                
                # Explicitly protect the analysis from being processed as a chat response
                st.session_state.analysis = copy.deepcopy(complete_analysis)
                st.session_state.current_analysis = copy.deepcopy(complete_analysis)
                
                # Track video URL for context maintenance
                st.session_state.current_video_url = video_url
                logger.info(f"Set current_video_url to: {video_url}")
                
                # Verify the stored analysis maintains its structure
                if 'analysis' in st.session_state:
                    print(f"Verified: Analysis stored with type: {type(st.session_state.analysis)}")
                    if hasattr(st.session_state.analysis, 'keys'):
                        print(f"Verified: Analysis contains keys: {list(st.session_state.analysis.keys())}")
                else:
                    print("WARNING: Analysis not properly stored in session state")

                # Debug the complete analysis structure
                print("Complete analysis keys:", complete_analysis.keys())

                # Add a timestamp to force cache refresh
                st.session_state.last_analysis_time = datetime.now().timestamp()

                # Create a brief summary for the chat interface
                video_title = analysis_result["metadata"].get("title", "Unknown video")
                channel = analysis_result["metadata"].get(
                    "channel_title", "Unknown channel"
                )

                # Format the duration and published date
                duration = format_duration(
                    analysis_result["metadata"].get("duration", "Unknown")
                )
                published_date = format_published_date(
                    analysis_result["metadata"].get("published_at", "Unknown")
                )

                # Get comment count if available
                comment_count = analysis_result["metadata"].get(
                    "comment_count", "Unknown"
                )

                response = f"ðŸŽ¬ Video Analysis Complete\n\n"
                response += f"**Title**: {video_title}\n\n"
                response += f"**Channel**: {channel}\n\n"
                response += f"**Duration**: {duration}\n\n"
                response += f"**Published**: {published_date}\n\n"
                
                # Format view count with commas for thousands - Force string formatting 
                view_count = analysis_result['metadata'].get('view_count', 'Unknown')
                if isinstance(view_count, (int, float)):
                    # Use formatted string with commas
                    view_count_str = f"{int(view_count):,}"
                    print(f"[analyze_video] Formatted view count: {view_count} -> {view_count_str}")
                    response += f"**Views**: {view_count_str}\n\n"
                else:
                    response += f"**Views**: {view_count}\n\n"
                
                # Format like count with commas - Force string formatting
                like_count = analysis_result['metadata'].get('like_count', 'Unknown')
                if isinstance(like_count, (int, float)):
                    # Use formatted string with commas
                    like_count_str = f"{int(like_count):,}"
                    print(f"[analyze_video] Formatted like count: {like_count} -> {like_count_str}")
                    response += f"**Likes**: {like_count_str}\n\n"
                else:
                    response += f"**Likes**: {like_count}\n\n"
                
                # Format comment count with commas - Force string formatting
                if isinstance(comment_count, (int, float)):
                    # Use formatted string with commas
                    comment_count_str = f"{int(comment_count):,}"
                    print(f"[analyze_video] Formatted comment count: {comment_count} -> {comment_count_str}")
                    response += f"**Comments**: {comment_count_str}\n\n"
                else:
                    response += f"**Comments**: {comment_count}\n\n"
                # Use the same overall score calculation as in the analysis section
                if 'factors' in score_result:
                    factors = score_result['factors']
                    available_scores = []
                    
                    # Get scores from all factors - same logic as in display_analysis_results
                    performance_categories = [
                        {"key": "hook_quality"},
                        {"key": "seo_optimization"},
                        {"key": "content_quality"},
                        {"key": "engagement_metrics"},
                        {"key": "technical_quality"}
                    ]
                    
                    for category in performance_categories:
                        factor_key = category["key"]
                        if factor_key in factors and "score" in factors[factor_key]:
                            try:
                                score_value = min(5.0, float(factors[factor_key]["score"]))
                                available_scores.append(score_value)
                            except (ValueError, TypeError):
                                pass
                    
                    # Calculate overall score using the same method as display_analysis_results
                    if available_scores:
                        computed_overall_score = sum(available_scores) / len(available_scores)
                        overall_score = min(5.0, round(computed_overall_score, 1))
                    else:
                        overall_score = min(5.0, float(score_result.get('overall_score', 0)))
                else:
                    overall_score = score_result.get('overall_score', 'N/A')
                    
                response += f"**Overall Score**: {overall_score}/5\n\n"

                # Add top 3 recommendations
                response += "### ðŸ’¡ Top Recommendations:\n"
                top_recommendations = recommendation_result.get(
                    "overall_recommendations", []
                )
                for i, rec in enumerate(top_recommendations[:3]):
                    response += f"{i+1}. {rec}\n"

                response += (
                    "\n*View the Analysis tab for complete details and scores.*\n"
                )
                response += "*Ask follow-up questions about this video in the chat!*"

                # Run the format_numbers_with_commas function for consistent formatting
                formatted_response = format_numbers_with_commas(response)
                
                # Additional safety check: directly scan for numbers to format in key metrics
                import re
                for metric in ['Views', 'Likes', 'Comments']:
                    pattern = f"\*\*{metric}\*\*: (\d+)"
                    matches = re.finditer(pattern, formatted_response)
                    for match in matches:
                        try:
                            num_str = match.group(1)
                            if ',' not in num_str:  # Only format if commas aren't already there
                                formatted_num = f"{int(num_str):,}"
                                old_text = f"**{metric}**: {num_str}"
                                new_text = f"**{metric}**: {formatted_num}"
                                formatted_response = formatted_response.replace(old_text, new_text)
                                print(f"[analyze_video] Forced metric formatting: {old_text} -> {new_text}")
                        except Exception as e:
                            print(f"[analyze_video] Error formatting {metric}: {str(e)}")
                
                # Log the formatted response for debugging
                print(f"[analyze_video] Final formatted response before adding to chat history: {formatted_response[:100]}...")

                # Add formatted analysis to chat UI - this is what the user will see immediately
                st.markdown(formatted_response)
                
                # Add to session state messages with the properly formatted response
                # This ensures formatting is preserved in the chat history
                st.session_state.messages.append(
                    {
                        "role": "assistant",
                        "content": formatted_response,
                        "video_url": video_url,
                        "type": "video_analysis",
                    }
                )
                
                # Save the conversation to persist the formatted message
                save_current_conversation()

                # Print debug information
                print(
                    f"Analysis data stored in session state with keys: {list(complete_analysis.keys())}"
                )
                print(
                    f"Metadata available: {list(complete_analysis.get('metadata', {}).keys())}"
                )
                print(f"Current analysis set and ready for contextual responses")

                # Save the conversation to history immediately after analysis is complete
                save_current_conversation()
                
                # Check if there's a pending question to answer after analysis
                if "pending_question" in st.session_state and st.session_state.pending_question:
                    print(f"[DEBUG_TRACE] Found pending question after analysis: {st.session_state.pending_question}")
                    question = st.session_state.pending_question
                    # Clear the pending question to avoid processing it multiple times
                    st.session_state.pending_question = None
                    
                    # Add the user's question as a new message
                    question_message = {
                        "role": "user", 
                        "content": question,
                        "video_url": video_url
                    }
                    st.session_state.messages.append(question_message)
                    
                    # Add thinking indicator
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": "ðŸ¤” Thinking...", 
                        "type": "thinking_indicator",
                        "video_url": video_url
                    })
                    
                    # Set up for response generation
                    st.session_state.current_processing_prompt = question
                    st.session_state.is_generating_response = True
                    
                    # Save state before rerunning
                    save_current_conversation()
                
                # Force UI update to refresh the sidebar with the new analysis
                st.rerun()

            except Exception as e:
                error_msg = f"Error analyzing video: {str(e)}"
                st.error(error_msg)
                st.session_state.messages.append(
                    {
                        "role": "assistant",
                        "content": f"âŒ {error_msg}",
                        "video_url": video_url,
                        "type": "error",
                    }
                )


def reformat_existing_messages():
    """Apply number formatting to all existing messages in session state."""
    if "messages" not in st.session_state:
        print("[reformat] No messages in session state")
        return
        
    # Get all messages
    messages = st.session_state.messages
    print(f"[reformat] Found {len(messages)} messages in session state")
    
    # Loop through messages and reformat content
    changes_made = False
    for i, message in enumerate(messages):
        if message.get("role") == "assistant" and "content" in message:
            # Apply formatting to the content
            content = message["content"]
            print(f"[reformat] Processing message {i}: {content[:50]}...")
            
            # Format numbers in the content
            formatted_content = format_numbers_with_commas(content)
            
            # Update the message content
            if formatted_content != content:
                print(f"[reformat] Updated message {i} with formatted numbers")
                messages[i]["content"] = formatted_content
                changes_made = True
    
    # Update session state only if changes were made
    if changes_made:
        print("[reformat] Updating session state with reformatted messages")
        st.session_state.messages = messages
        
        # Also update the conversation history to persist the changes
        print("[reformat] Saving changes to conversation history")
        save_current_conversation()
    else:
        print("[reformat] No formatting changes were needed")
        
    # Force re-display of messages if needed
    if changes_made:
        try:
            st.rerun()
        except AttributeError:
            # Fallback for older Streamlit versions
            try:
                st.experimental_rerun()
            except:
                # If neither method works, just continue without rerunning
                print("[reformat] Could not force rerun - continuing without refresh")
                pass

def main():
    """Main function to run the Streamlit app."""
    load_chat_history()
    init_session_state()
    
    # Apply formatting to existing messages
    reformat_existing_messages()
    
    setup_ui()

    # Create tabs for chat and analysis
    tab1, tab2 = st.tabs(["ðŸ’¬ Chat", "ðŸ“Š Analysis"])

    # Display chat in the Chat tab
    with tab1:
        display_chat()
        
        # Handle user input with the chat input box
        user_prompt = st.chat_input("Paste a YouTube URL or ask a question...")
        
        # Only process user input if something was entered and we're not mid-processing
        if user_prompt and not st.session_state.get("is_generating_response", False):
            # Process the user input - this now handles URL detection and manages url_question_answered flag
            process_user_input(user_prompt)
        
        # Always call handle_user_input to manage ongoing response generation
        # This function will check the url_question_answered flag and other state variables
        handle_user_input()

    # Add a debug message to verify the app is running properly
    st.sidebar.caption(f"Last app refresh: {datetime.now().strftime('%H:%M:%S')}")
    print(f"App refreshed at {datetime.now().strftime('%H:%M:%S')}")

    # Display analysis in the Analysis tab if available
    with tab2:
        # Add debug information about analysis data
        print(f"Analysis data available: {'analysis' in st.session_state}")
        if 'analysis' in st.session_state:
            print(f"Analysis data type: {type(st.session_state.analysis)}")
            if st.session_state.analysis:
                print(f"Analysis keys: {st.session_state.analysis.keys() if hasattr(st.session_state.analysis, 'keys') else 'No keys method'}")
        
        if st.session_state.analysis:
            # Add a message to confirm we're trying to display analysis
            print("Attempting to display analysis results...")
            display_analysis_results(st.session_state.analysis)
        else:
            st.info(
                "No analysis results available yet. Paste a YouTube URL in the chat to analyze a video."
            )
            st.caption(
                "Once analysis is complete, results will appear here automatically."
            )


if __name__ == "__main__":
    main()
